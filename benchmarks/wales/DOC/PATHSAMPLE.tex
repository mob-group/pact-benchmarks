% <preamble>
\documentclass[12pt,a4paper,dvips]{article}
\usepackage{mathptm,graphicx,xspace,overcite,here}
\usepackage[bookmarksnumbered=true]{hyperref}

% \renewcommand{\baselinestretch}{1.5}
\def\mydash{${-}$}
\newcommand{\etal}{{\it et al.}}
\newcommand{\D}{\displaystyle}
\sloppy

% </preamble>
% <frontpage>
% </preamble>
% <document>
% <frontpage>
\begin{document}
% \input{laspec}

\title{{\tt PATHSAMPLE} User Guide}
\author{David J.~Wales}
\date{Last updated \today}
\maketitle

\clearpage
\phantomsection
\pdfbookmark[0]{\contentsname}{contents} % Sets a PDF bookmark for the Table of Contents
\tableofcontents
% </frontpage>
% <intro>
\section{Introduction}
\label{sec:intro}

{\tt PATHSAMPLE} is the {\tt OPTIM} driver program to implement a
discrete path sampling (DPS) construction of stationary point 
databases and perform kinetic analysis.\cite{wales02,Wales03,wales04,TrygubenkoW06,Wales06}
This implementation provides a number of different methods for growing stationary 
point databases in order to produce samples that are kinetically relevant.
The main difference from the old version {\tt PATHSAMPLE.2.0} is that the geometrical test for
distinguishing stationary points has been changed to use the minimum distance.
This usage is consistent with {\tt OPTIM} and the tolerance is set using the
keyword {\it GEOMDIFFTOL}. Subsequent enhancements of the code are not implemented
in {\tt PATHSAMPLE.2.0}.

{\tt PATHSAMPLE} relies upon {\tt OPTIM} \cite{optim} to perform geometry optimisation, 
especially double-ended searches for pathways between specified minima. 
In the simplest case, all the {\tt OPTIM} calls will be Dijkstra connect runs
\cite{CarrTW05} (this is the case if the {\it CONNECTIONS} parameter is less than or equal to one,
see \S \ref{sec:keywords}).
Please refer to the {\tt OPTIM} documentation for full details of this program \cite{optim}.

The DPS technique is designed to calculate rate constants
between two different regions (A and B) on the potential energy surface, 
where a region is defined by a set of local minima.\cite{wales02,Wales03,wales04,TrygubenkoW06,Wales06,
EvansW03b,EvansW04,CarrW05}
In {\tt PATHSAMPLE.2.0} and above, this objective is achieved by building up
a stationary point database using successive double-ended connection runs between
local minima, where connections are chosen according to the minimum distance 
between the minima and their predicted committor probabilities.
Note that that this approach is different from the original philosophy,
which focused upon the rates associated with individual discrete paths and created 
new paths by perturbing old ones.

% <changes>
\section{Recent Changes}
\label{sec:latest}

All the {\it TRIPLES\/} keywords have been retired, i.e.~{\it TRIPLES\/}, {\it ADDTRIPLES\/}, 
{\it STARTTRIPLES\/}. These should be removed from all {\tt pathdata} files in
the future. All {\tt path.info} files produced by {\tt OPTIM} are now in
the triples format, whether generated by {\it DUMPPATH\/} or {\it DUMPALLPATHS}.
This change means that the {\tt getallpaths} subroutine is used to read all
{\tt path.info} files, and that the {\tt getnewpath} routine is obsolete.

{\it DIJINITSTART\/} and {\it DIJINITCONT\/} can now have an additional argument to
specify the number of entries in the sorted list of metric values that is dumped in
file {\tt pairdist}.

The {\it NGT} keyword has been added for a new graph transformation procedure. 
This routine can calculate $k^{\rm SS}$, $k^{\rm NSS}$ and $k^{\rm KMC}$ for both
$A\leftarrow B$ and $B\leftarrow A$, as well as committor probabilities, in one call.
This is now the recommended way to calculate rate constants.

The {\it DIJINIT\/} keyword has been replaced by two separate keywords,
namely {\it DIJINITSTART\/} and {\it DIJINITCONT\/}, to simplify the generation of
initial paths. 

{\it DIJINITSTART\/} is intended for automatic setup of the {\tt min.A}, {\tt min.B},
{\tt min.data}, {\tt ts.data}, {\tt points.ts} and {\tt points.min} files from initial
{\tt odata.start} and {\tt odata.finish} files. In contrast to the previous 
philosophy, {\it DIJINITSTART\/} will {\bf overwrite database files if they already exist}.
Hence it is possible to wipe an existing database with this keyword.

{\it DIJINITCONT\/} is intended for continuation of initial path searches that have not yet 
completed. It can also be used to start a run if the required database entries for two
end points have been created by hand. {\it DIJINITCONT\/} will check that the required
files are present in the current working directory, and stop if they are not.

The MFPT calculation for the fastest steady-state path (ignoring recrossings)
in a {\it DIJKSTRA} calculation
has been changed to the graph transformation approach.\cite{TrygubenkoW06}

The printing of rate constants at the end of a {\it GT\/} calculation has been changed
to make it clear which values are calculated assuming that detailed balance holds.
An extra summary line with the non-detailed balance rate constants is printed at the end.

After each cycle over the available CPU's {\tt PATHSAMPLE} will now check to see if the
file {\tt pathdata.change} exists in the current working directory. 
If it does, then {\tt pathdata.change} is copied to {\tt pathdata}
and all parameters are reread using {\bf keyword}.
This feature is designed to allow for change of parameters during a run without
the need to kill and requeue a job. 
Attempts to change variables that affect declarations of array bounds will 
cause the program to crash.

%</changes>
\section{Input files}
\label{sec:input}
The following files are required in the directory where {\tt PATHSAMPLE} is executed.
\smallskip
\begin{itemize}
\item {\tt pathdata}: contains parameters to control the stationary point
sampling and/or the kinetic analysis. See \S\ref{sec:keywords}.
\item {\tt odata.*} files: the {\tt odata} file is the control file for {\tt OPTIM}. 
One {\tt odata} file is
needed for each type of {\tt OPTIM} job performed by {\tt PATHSAMPLE}. See \S\ref{sec:odatafiles}.

\item {\tt commit.data}. This file is updated every time a committor probability 
calculation is performed. Initial committor probabilities are read from it if the
file is detected. Otherwise, the initial values are 
set to zero and one as appropriate.
If a {\tt PATHSAMPLE} run ends abnormally it is possible for the number of entries
in {\tt commit.data} to be less than the number of local minima in {\tt min.data}.
In this case the missing values are automatically
set to zero. This procedure does not work with some compilers
if they behave incorrectly on reaching the end of file.
In this case the missing zeros can simply be added using a text editor.

\end{itemize}

The following files may be required, depending upon the keywords set in {\tt pathdata}:
\smallskip
\begin{itemize}
\item {\tt min.A}, {\tt min.B} and {\tt min.data}: lists of A, B and intermediate minima, respectively. 
The first line of {\tt min.A} is the number of A minima (free format), $N_{\rm A}$; on the following lines
there must be $N_{\rm A}$ integers (free format), which specify all the local minima 
belonging to the A set. Hence, the A region can be changed simply by editing this file.
{\tt min.B} has the same format for the B minima.
The numbering of the local minima must be consistent with the order of their
coordinates in {\tt points.min} (see below).
However, unlike older versions of {\tt PATHSAMPLE}, the A and B minima can appear 
in any order, facilitating regrouping schemes.
The file {\tt min.data} has the format:

{\it energy\quad frequency\quad pgorder\quad itx\quad ity\quad itz}

for each minimum, where $energy$ is the potential energy (as calculated by {\tt OPTIM}), 
$frequency$ is the natural log of the
product of positive eigenvalues from the mass-weighted Hessian
(used to evaluate partition functions and rates constants), $pgorder$ is the order of the point group,
and $itx, ity, itz$ are the (sorted) eigenvalues of the inertia tensor.
The order of entries in {\tt min.data} must agree with the {\tt min.A},
{\tt min.B} and {\tt points.min} files.

\item The file {\tt ts.data} is analogous to the {\tt min.data} file, 
but contains data for the transition states. The format is: 

{\it energy\quad frequency\quad pgorder\quad min1\quad min2\quad itx\quad ity\quad itz} 

where the entries are the same as for the minima, with the addition of {\it min1} and
{\it min2}, which identify the minima that the transition state connects. 
This file must be consistent with {\tt points.ts} (see below).

\item {\tt points.min}: contains the Cartesian coordinates of all the minima that are specified in 
{\tt min.data} in the same order. It is 
an unformatted direct access file, written with the Fortran specifier 
{\tt RECL=8*3*NATOMS}. 

\item {\tt points.ts}: as for {\tt points.min}, but contains the transition state 
coordinates.

\item {\tt nodes.info}: must be present for runs on a distributed memory machine.
The first line must contain an integer equal to the number of nodes available,
and the names of these nodes must follow below. 
On the final line the userid must be provided.
An example script for the qsub command could look like:
\begin{table}[H]
\begin{center}
\begin{tabular}{l}
\#!/bin/csh \\
\#PBS -q h4 \\
cd \$PBS\_O\_WORKDIR \\
cat \$PBS\_NODEFILE $>$\& output \\
wc output $>$ nodes.info \\
cat \$PBS\_NODEFILE $>>$ nodes.info \\
echo \$USER $>>$ nodes.info \\
/home/bin/pathsample $>>$\& output \\
\end{tabular}
\end{center}
\end{table}

\item {\tt path.info.startup}: an {\tt OPTIM} {\tt path.info}
file from a connect run that connects an A minimum to a B minimum.
Note that an output file is not required, unlike older versions of {\tt PATHSAMPLE}.
This file is needed to
provide an initial path, and the file name startup is specified in the {\tt pathdata} file
by the {\it STARTFROMPATH} keyword.
If the files {\tt min.A} and {\tt min.B} are absent, then {\it STARTFROMPATH}
will create them, with a single minimum specified in each region, corresponding
to the entries specified on the {\it STARTFROMPATH} line after the file extension
startup.
The rest of the minima read from the
{\tt path.info.startup} file will be placed in the intervening set.
Note that for {\tt path.info} files in the new {\tt OPTIM}
{\it DUMPALLPATHS} format, the two end point minima will generally not
be the first and last entries.
Since {\tt min.data} contains only unique minima, whereas the {\tt path.info} file may have
duplicates, the positions of the starting and finishing minimum may not be obvious.
A quick way to check these values is to run {\tt PATHSAMPLE} first with {\it CYCLES 0},
find the positions of the two minima in {\tt min.data} and correct
the values in {\tt pathdata}, remove {\tt min.*}, {\tt points.*}
and {\tt *.data}, and start the real {\tt PATHSAMPLE} run.
% If the {\tt path.info.startup} file is in the new {\it DUMPALLPATHS} format
% then {\tt pathdata} must contain the keyword {\it STARTTRIPLES}.
For a setup where the A and B sets are predefined in {\tt min.A} and {\tt min.B}
a connecting pathway can be read using the keyword {\it ADDPATH add} in {\tt pathdata}.
A path will then be read from file {\tt add}.
% ; if this path is
% in the new {\it DUMPALLPATHS} format then the keyword {\it ADDTRIPLES} must
% be present in {\tt pathdata}.
\end{itemize}

The {\tt min.data}, {\tt ts.data}, {\tt points.min} and {\tt points.ts} files are 
updated by {\tt PATHSAMPLE} as new minima and transition states are found. 

\section{Keywords: the {\tt pathdata} file}
\label{sec:keywords}
Input is keyword driven with sensible defaults in most cases. See the source {\bf keyword.f} if in doubt.
The following keywords are recognised, where {\it n\/}, {\it x\/} and {\it a\/} are integer,
real and character data, respectively. A line beginning with {\it COMMENT} is ignored.
\smallskip
% </intro>
% <kwd>
\begin{itemize}
\item {\it ADDMIN file\/}: reads in the data for one or more minima from {\it file}
in {\tt OPTIM} min.data.info format and then stops. 
Any number of min.data.info files can be concatenated into {\it file}.
New entries will be created in {\tt min.data} and {\tt points.min}.
If {\tt min.A} and {\tt min.B} do not exist they are not created.
{\it READMIN} therefore provides an alternative way to start an initial
path calculation by providing minima, so long as {\tt min.A} and {\tt min.B}
are created by hand.
It also provides a way to add additional minima to an existing database, since
new entries should be appended. There is a check to make sure that the minima
added are different from all those currently known.
This keyword has the same function as {\it READMIN\/} and is provided for convenience.

\item {\it ADDMINXYZ file\/}: reads coordinates in xyz format from
file {\it file\/} and runs {\tt OPTIM} for each one using {\it odata.addminxyz\/},
which needs to contain the {\tt OPTIM} keywords {\it DUMPDATA\/} and {\it ENDHESS\/}
so that a {\it min.data.info\/} file is created.
The resulting {\it min.data.info\/} files are then used to add minima to the
database, which can be empty initially. CYCLES must also be set to a non-zero value.

\item {\it ADDPATH afile \/}: reads pathway data from file {\tt afile}. 
If {\it ADDPATH\/} is used on its own before a connection has been
achieved then {\it DIJINITCONT\/} should be specified so that the
{\tt pairdist} and {\tt pairlist} files are written.

% If this 
% file is in {\it DUMPALLPATHS} format then the keyword {\it ADDTRIPLES} is also needed.

\item {\it ADDPERM\/}: adds permutational isomers of every 
stationary point to the databases. Not recommended except for small systems
where you are using a tagged atom to study an isomerisation (e.g. 2D LJ7).

\item {\it ADDPERM2 start finish\/}: adds all distinct permutation-inversion isomers of every 
stationary point to the databases for permutations of atoms numbered from
{\it start\/} to {\it finish\/}, inclusive. Not recommended except for small systems!
Added this capability to allow studies where permutation-inversion isomers are
not automatically lumped togther, to see the effect of free energy regrouping
(or observation time scale) on the landscape.
Any {\tt perm.allow} file present is ignored.

\item {\it ADDPERM3\/}: adds all distinct permutation-inversion isomers of every 
stationary point to the databases according to the allowed permutations in
{\tt perm.allow}.
Can be used in combination with {\it MERGEDB\/} to create a new database where
permutation-isomers are distinguised.

% \item {\it ADDTRIPLES \/}: specifies that the {\tt afile} file to be read
% according to the {\it ADDPATH afile} keyword is in 
% {\it DUMPALLPATHS} format.

\item {\it ALLOWAB\/}: allows minima to belong to both A and B sets where lumping
is performed with {\it REGROUPFREE\/} and {\it RFMULTI\/}. 
This may be useful for understanding how free energy groups merge as a function of
observation time scale and temperature, when rate constants are not required.

\item {\it ALLTS \/}: specifies that transition states that are considered identical by energy 
and geometry conditions to one already in the database, but which connect different minima are not discarded
and are treated as a new transition state. This is especially useful when starting PATHSAMPLE from an 
OPTIM path.info file using {\it STARTFROMPATH} and {\it STARTTRIPLES}, as the path.info file from 
OPTIM may contain such transition states, even if only one is involved in the connected path.

\item {\it ANGLEAXIS \/}: specifies angle-axis coordinates for rigid bodies. NB: this is not part of the GENRIGID framework.

\item {\it AMBER9 \/}: specifies the AMBER 9 potential.

\item {\it AMH \/}: specifies an AMH potential.

\item {\it AMHQ whichmin \/}: Calculates Wolynes Q score based on the native state structure.

\item {\it AMHRMSD whichmin \/}: Calculates RMSD based on the native state structure.

\item {\it AMHQCONT whichmin rcut \/}: Calculates Q-cutoff score based on a native distance. 

\item {\it AMHRELQ whichmin1 whichmin2 \/}: Calculates Wolynes Q score between two minima. 

\item {\it AMHALLATOM \/}: Adds sidechains and completes backbone for AMH structures with SCWRL. 
Input structure is amhmin.pdb. Output structure is amhmin.pdb.scwrl. Scwrl output logs scwrl\_out.

\item {\it AMH\_RELCO whichmin rcut \/}: Calculates relative contact order for AMH structures.

% \item {\it BREADTH\/}: breadth-first analysis to find the shortest A$\leftrightarrow$B paths.
% {\bf Not implemented yet}.


\item {\it ATOMMATCHDIST}: Currently for bulk systems only, providing an alternative method for finding the shortest distance between structures.
This method is particularly useful for finding the shortest distance between very similar structures such as defective crystal structures.
The method is an extension of the original bulkmindist.f90 routine for matching permutational isomers. Atoms are overlayed and the number of exactly matching atoms is maximised. 
With {\it ATOMMATCHDIST}, the method is non-deterministic to maximise efficiency. It has been optimised to work particularly well for providing small distances
  between similar structures and for removing very large distances. However, it will not always outperform the default method for middling distances.    
Currently only one method for calculating distances, atom matching or the default, can be used.  

\item {\it ATOMMATCHFULL}: As for {\it ATOMMATCHDIST}, but provides a slow deterministic result that should always outperform or equal the default distance calculation and {\it ATOMMATCHDIST} but may never finish.


\item {\it BHINTERP dthresh maxe bhsteps conv T stepsize accrat K sfrac ICINTERP\/}: specifies that
{\tt OPTIM} jobs should be run using only the {\it BHINTERP} interpolation option,
where no transition state searches are run. Requires the auxiliary file {\tt odata.bhinterp}.
This option is intended for use with {\it DIJINITSTART} and {\it DIJINITCONT}.
The various arguments are used to add a {\it BHINTERP} line to the {\tt OPTIM} {\tt odata} file.
The distance threshold parameter specifies that interpolation between consecutive minima
in the Dijkstra list should occur if their minimum distance is greater than {\it dthresh}. 
The threshold actually used in the corresponding {\tt odata} file is either the minimum distance
divided by two or {\it dthresh}, whichever is greater. This arrangement enables 
parallel {\tt OPTIM} jobs to be run for different pairs of minima.
Intermediate minima are only accepted if their energy is below {\it maxe}.
A basin-hopping global optimisation run of {\it bhsteps} is run for each pair of
end point minima within {\it dthresh\/} using an RMS gradient convergence criterion
of {\it conv\/}, a temperature parameter of {\it T\/}, and a maximum step size for
perturbations of {\it stepsize\/}. The step size is adjusted dynamically towards an
acceptance ratio target of {\it accrat\/}.  
The objective function consists of the energy of the minimum on the potential energy surface
plus the energy corresponding to harmonic springs of force constant {\it K\/} 
stretched to displacements corresponding to the minimum distance between the new minimum
and the end points.
{\it sfrac\/} is used in the initial interpolation: a value of 0.5 will put the initial
guess half-way between the end points, and in general the geometry will be {\it sfrac\/} times one
end point plus $(1-${\it sfrac\/}$)$ times the other.
For large distances, using a value other than a half may be helpful.
If {\it ICINTERP\/} is present then amino acid side chains are interpolated using
internal coordinates for CHARMM runs.
The step size is interpreted in degrees for CHARMM, where the perturbations used
to step between minima are performed using dihedral angle twists.
The algorithm is applied recursively between minima as new minima are found.
A new minimum will not be accepted if both distances to the minima we are
currently trying to interpolate between are greater than the minimum distance
between these minima.

\item {\it BISECT dthresh maxe bisectsteps attempts ICINTERP\/}: specifies that
{\tt OPTIM} jobs should be run using only the {\it BISECT} interpolation option,
where no transition state searches are run. Requires the auxiliary file {\tt odata.bisect}.
This option is intended for use with {\it DUMMYTS}.
The various arguments are used to add a {\it BISECT} line to the {\tt OPTIM} {\tt odata} file.
The distance threshold parameter specifies that bisection between consecutive minima
is attempted if their minimum distance is greater than {\it dthresh}. 
The interpolated geometry is minimised and compared with the starting structures.
New minima are only accepted if their energy is below {\it maxe}; they are added to the
current list of known minima in the {\tt OPTIM} job between the two starting structures.
The estimated energy of any dummy transition states between the two starting structures
is raised if the sum of distances between the new minimum and the two structures is
greater than the original minimised distance.
{\it bisectsteps\/} is the maximum number of bisection steps, and
{\it attempts} is the number of attempts per step for a given pair.
If minimisation leads to one of the end points the interpolation is changed to use 
fractions of the two structures that become increasingly skewed, as for
the adjustment of {\it sfrac\/} with {\it BHINTERP\/}, above.
The {\tt ts.data} file is rewritten if the any dummy transition state energies are revised.
If {\it ICINTERP\/} is present then amino acid side chains are interpolated using
internal coordinates for CHARMM runs.

\item {\it BULK x1 x2 x3\/}: a bulk system in a periodic box of lengths {\it x1, x2, x3\/}.

\item {\it CALCORDER\/}: the program will call subroutine {\bf calcorder.f90} and calculate
order parameters, before exiting. Since the order parameters will be system dependent 
users must compile in an appropriate {\bf calcorder.f90} themselves.

\item {\it CAPSID rho eps rad h\/}: parameters for a rigid pentagonal pyramid. If $h$ is omitted
it is set to half $rad$ by default.

\item {\it CHARMM}: specifies that the CHARMM potential is used in the {\tt OPTIM} runs.

\item {\it CHECKCONECTIONS\/}: instruction to check that each minimum has at least the number
of connections specified by the {\it CONNECTIONS\/} keyword at the start of every run,
before anything else is done. See {\it CONNECTIONS\/} below.
This keyword results in calls to the original single-ended transition state
searching subroutine, which is not efficiently parallelised.
The {\it NEWCONNECTIONS\/} keyword should probably be used instead.

\item {\it CHECKMIN start finish\/}: will rerun {\tt OPTIM} for all the
minima from {\it start\/} to {\it finish\/} using the odata file
{\tt odata.checksp}, which must be present in the working directory. 
{\tt PATHSAMPLE} will report whether or not the {\tt OPTIM} job converged, so the number 
of minimization steps should be set accordingly (e.g. {\it BFGSSTEPS 0}).
This option may be useful for finding any unconverged minima in a corrupted database,
which could then be removed using {\it REMOVESP}.

\item {\it CHECKTS start finish\/}: will rerun {\tt OPTIM} for all the
transition states from {\it start\/} to {\it finish\/} using the odata file
{\tt odata.checksp}, which must be present in the working directory. 
{\tt PATHSAMPLE} will report whether or not the {\tt OPTIM} job converged.
{\tt odata.checksp} should probably be the same as for {\it CHECKMIN}, as in, a minimization 
with zero steps where only the initial energy and gradient are calculated to test for convergence 
and the Hessian index is NOT checked.
This option may be useful for finding any unconverged transition states in a corrupted database,
which could then be removed using {\it REMOVESP}.

\item {\it CLOSEFILES\/}: open and close the {\tt min.data} and {\tt ts.data} files as needed.
By default these files stay open all the time. For small systems this inevitably seems to cause
file corruption on nfs mounted file systems, which is apparently due to bugs in the interaction
of nfs with the Linux kernel. The symptom is that strings of control characters appear randomly in
{\tt min.data} and/or {\tt ts.data}, which means that the run cannot continue without
manually fixing the file in question.
The {\tt CLOSEFILES} keyword has provided a successful workaround for this problem.

\item {\it CONNECTIONS n maxattempts\/}: minimum number of connections for each minimum. 
For each new minimum found {\tt PATHSAMPLE} will attempt to find {\it n\/} connected minima.
If {\it n} is one or fewer then no additional single-ended transition state searches are
needed, and the more efficient {\bf cycle2.f90} subroutine is used. In this case, {\tt OPTIM}
jobs do not have to be processed in batches; instead, a new {\tt OPTIM} job is submitted
as soon as one finishes. The default for {\it n} is now 0.
The maximum number of transition state searches from each new minimum is {\it maxattempts}, 
for which the default is 10.
Note that you will need file {\tt odata.tssearch} in the current
working directory if {\it n} is greater than one.
The {\tt odata.tssearch} file needs to contain OPTIM {\it PATH} 
and {\it DUMPALLPATHS\/} directives
so that a {\tt path.info} file is created.
It is no longer necessary to supply a separate {\tt odata.path} file.
This keyword results in calls to the original single-ended transition state
searching subroutine, which is not efficiently parallelised.
The {\it NEWCONNECTIONS\/} keyword should probably be used instead.

\item {\it CONNECTPAIRS connectfile\/}: minima are chosen for connection attempts based
on the pairs specified in file {\tt connectfile}, which must have two integers per line
corresonding to the order in {\tt min.data}.

\item{\it CONINT\/} specifies that terms for internal minimum distances
should be included in the energy and gradient for the auxiliary interpolation
potential when {\it INTCONSTRAINT\/} is specified.

\item {\it CONNECTREGION min1 min2 dist\/}: grows the stationary point database by running
double-ended transition state searches between minima whose minimum separation is less then
{\it dist}. {\it min1} and {\it min2} specify the starting minima in the double loop over
pairs, so that restarted runs need not consider pairs that have previously been searched.
Minima that already have a direct connection are ignored.
The maximum number of candidate pairs calculated per call to {\bf connectd.f90} is 10000.
This parameter may be useful for exhaustive searches for small systems.

\item {\it CONNECTUNC option (refmin)\/}: attempt to connect minima not connected to the AB region.
{\it option} specifies one of three options (no default set): {\it LOWEST (n)} attempts connections of the lowest 
energy minima with the {\it n} closest minima in the AB set, {\it EREF refmin} attempts connections
of the minimum {\it refmin} with the minima closest in energy, {\it DISTREF refmin} does the same using 
the closest minima in distance to {\it refmin}.

\item {\it COPYFILES a1 a2 a3 $\ldots$\/}: specify additional files that need to be
copied to distributed nodes. Only files {\tt odata.<pid>} and {\tt finish.<pid>} are
copied by default. For example, the BLN potential requires file {\tt BLN sequence}, while
CHARMM runs may need one or more {\tt crd} files. Each string must be less than or equal to
twenty characters in length, and the total, including separating blanks, must not exceed
80 characters. If the {\it CHARMM\/} keyword is set and the {\it COPYFILES\/} 
arguments do not include {\tt input.crd} then the program will stop.

\item {\it COPYOPTIM\/}: if present, some of the {\tt OPTIM} output files will be copied to
the mother superior node and not deleted. This behaviour also occurs if the {\it DEBUG\/}
keyword is present. The copied files, in addition to {\tt path.info} ({\tt min.data.info} 
for a {\it BHINTERP\/} run), are the {\tt OPTIM} output file, the {\tt odata} file
and the {\tt finish} file.

\item {\it CPUS ncpu}: specifies the number of cpu's (cores) available when running 
{\tt PATHSAMPLE} interactively, without using a scheduler such as PBS to
send jobs to distributed memory nodes. If used on
a distributed memory cluster then {\it n} {\tt OPTIM} jobs will be run at any given
time, and they will all run on the interactive node in question.
Can be used to run multiple {\tt OPTIM} jobs on an interactive testing node of a distributed memory
machine.

\item {\it CUDA \/}: should be used with keyword SLURM when running GPU jobs on pat. 

\item {\it CYCLES n}: the number of cycles of {\it ncpu} or
{\it jpn}$\times$nodes {\tt OPTIM} jobs to run in sampling the stationary point
database.

\item {\it CV Tmin Tmax Tinc}: calculate the heat capacity in the harmonic
superposition approximation from temperature {\it Tmin\/} to {\it Tmax} at
intervals of {\it Tinc}.

\item {\it CVMINIMA minstart minend mininc}: must be used in conjunction with
{\it CV} above.
Calculate the heat capacity as per the {\it CV} keyword using sums of local minima
ordered in terms of increasing potential energy.
The first calculation will sum up to minimum {\it minstart}, the next
will sum up to {\it minstart + mininc}, etc., until we reach
{\it minend}.
This keyword provides an automated way to break down the contributions to $C_v$.

\item {\it DB sigmabb}: calls
a finite system of dipolar Lennard-Jones dumbbells \cite{ChakrabartiFW09}, where 
$\sigma$'s correspond to the Lennard-Jones parameters. $\sigma_{aa}$ is set to unity by default.

\item {\it DEBUG\/}: turn on debug printing.

\item {\it DEGFREEDOMS n}: used to specify the number of degrees of freedom, {\it n}, in the system. This 
should not be used with {\it RIGIDINIT}. Instead, the number of degrees of freedom should be specified as an argument
to that keyword.

\item {\it DGT DisconnectSources AltPbb Rescale Normalise\/}: 
dense optimised graph transformation rate calculation \cite{TrygubenkoW06}.
The four arguments are all logicals, so an example input line might look
\vbox{DGT T T F F}. If true (the default) {\it DisconnectSources} specifies that
a full transformation should be performed for each source, disconnecting the 
other sources. The resulting rate constants correspond to the KMC result and
$k^{\rm KMC}$ \cite{Wales06}.
If {\it AltPbb\/} is true (default is false) then additional work is done to
maintain precision, which roughly doubles the execution time, but may be needed at low
temperature.
If {\it Rescale} is true (default false) an alternative strategy is used 
to try and prevent error propagation.
Setting {\it Normalise} true (default false) instructs {\tt GT2input.f90} to check the normalisation
of branch probabilities. This should not be necessary.

\item {\it DIJINITCONT exp or n max p1 p2\/}: continue an initial Dijkstra connection 
from information in the existing {\tt min.A}, {\tt min.B}, {\tt min.data},
{\tt ts.data}, {\tt points.ts} and {\tt points.min} files.
The minimum information required consists of database entries 
for the two endpoint minima.
The algorithm used is similar to {\tt OPTIM}, except that the missing connections can
be sought in parallel {\tt OPTIM} runs, each of which is itself a separate
Dijkstra connect calculation.
If {\it exp} appears after {\it DIJINIT\/} then the edge weights are based on the
exponential distance; otherwise the distance is raised to the power {\it n}, which
defaults to 2.
The {\it max} parameter (default 10) specifies the number of entries for each
minimum in the sorted list of metric values (default metric is distance).
These values are now dumped in the file {\tt pairdist} with the identities of the
minima stored in file {\tt pairlist}.
This scheme enables much faster restarts if the number of minima grows large before
a connection is found, and limits the memory used to linear scaling rather than quadratic.
If {\it ADDPATH\/} is used on its own before a connection has been
achieved then {\it DIJINITCONT\/} should be specified so that the
{\tt pairdist} and {\tt pairlist} files are written.
If the same connection is attempted more than once the same {\tt odata} file
is used, and the previous calculation is simply duplicated.
The number of parallel searches is equal to the number of processors available.
For the first cycle all the searches would be the same, because there must be a single 
gap between the two end minima.
To avoid unnecessary duplication it is best to perform an initial run on
one processor, or a single node, for one cycle (see {\it DIJINITSTART\/} below). 
Then restart by simply increasing the number of cycles in the {\tt pathdata} file
as well as the number of processors.
In the Dijkstra analysis minima with zero connections are removed. 
This value can be changed using a {\it DIJKSTRA n} line in {\tt pathdata}.
If {\it p1} and {\it p2} are specified then {\tt PATHSAMPLE} will calculate the
{\tt pairlist} and {\tt pairdist} entries for minima in the range {\it p1} to
{\it p2} (inclusive) write them to files {\tt pairlist.p1.p2} and {\it pairdist.p1.p2},
and stop.

\item {\it DIJINITCONTFLY exp or n\/}: performs the same function as {\it DIJINITCONT} but
calculates distances between local minima on the fly. This approach may be necessary 
for initial path runs that produce more that 20,000 minima, where fitting all the 
distances into memory becomes an issue.

\item {\it DIJINITSTART exp or n max\/}: perform an initial Dijkstra connection run 
for the two endpoints specified in {\tt odata.start} and {\tt odata.finish}. 
In this case the files {\tt min.A}, {\tt min.B}, {\tt min.data}, {\tt ts.data} (and all
points files) will be created automatically.
{\bf Any existing database information will be overwritten}.
Note that the {\tt odata.start} and {\tt odata.finish} files must contain
the {\tt OPTIM} keyword {\it DUMPDATA\/} and calculate the normal mode frequencies.
For a CHARMM run the files {\tt start.crd} and {\tt finish.crd} are also needed.
The algorithm used is similar to {\tt OPTIM}, except that the missing connections can
be sought in parallel {\tt OPTIM} runs, each of which is itself a separate
Dijkstra connect calculation.
If {\it exp} appears after {\it DIJINIT\/} then the edge weights are based on the
exponential distance; otherwise the distance is raised to the power {\it n}, which
defaults to 2.
The {\it max} parameter (default 10) specifies the number of entries for each
minimum in the sorted list of metric values (default metric is distance).
These values are now dumped in the file {\tt pairdist} with the identities of the
minima stored in file {\tt pairlist}.
If {\it ADDPATH\/} is used on its own before a connection has been
achieved then {\it DIJINITCONT\/} should be specified so that the
{\tt pairdist} and {\tt pairlist} files are written.
This scheme enables much faster restarts if the number of minima grows large before
a connection is found, and limits the memory used to linear scaling rather than quadratic.
If the same connection is attempted more than once the same {\tt odata} file
is used, and the previous calculation is simply duplicated.
The number of parallel searches is equal to the number of processors available.
For the first cycle all the searches will be the same, because there must be a single 
gap between the two end minima.
To avoid unnecessary duplication it is usual to perform the first cycle of an initial
connection attempt on one processor for one cycle. 
Then restart using {\it DIJINITCONT\/} 
by simply increasing the number of cycles in the {\tt pathdata} file
as well as the number of processors.
For the first cycle it is also a good idea to use just one double-ended connection
cycle in {\tt odata.connect}, and increase this value on subsequent cycles
when some intervening minima are known. 
Otherwise the first {\tt OPTIM} job may spend a great deal of time performing
connection attempts that could be spread over multiple processors in a
{\tt PATHSAMPLE} {\it DIJINITCONT\/} job.
In the Dijkstra analysis minima with zero connections are removed. 
This value can be changed using a {\it DIJKSTRA n} line in {\tt pathdata}.

\item {\it DIJINITSTARTFLY exp or n\/}: performs the same function as {\it DIJINITSTART} but
calculates distances between local minima on the fly. This approach may be necessary 
for initial path runs that produce more that 20,000 minima, where fitting all the 
distances into memory becomes an issue.

\item {\it DIJKSTRA n\/}: perform a Dijkstra analysis to find the path
with the largest contribution to the `SS' rate constant ignoring recrossings. Minima with
{\it n} connections or fewer are pruned.
If {\it REGROUPFREE}, {\it REGROUPRATE}, or {\it REGROUPPE} is present
in {\tt pathdata} then the stationary points will be regrouped first. In this
case the energies in {\tt Epath} are free energies, and files such as
{\tt redopoints} and {\tt stationary.points} are not produced.
Once a path is found the rate corresponding to that path in isolation,
i.e.~ignoring other connections, is calculated using the graph transformation
method.\cite{TrygubenkoW06}.

\item {\it DIJKSTRAWAIT\/}: perform a Dijkstra analysis to find the path
with the lowest sum of waiting times times initial conditional probability.

\item {\it DIJPAIR n1 n2 string\/}: choose pairs of minima for connection attempts based on
the highest barrier on the path that makes the largest contribution
to the `SS' rate constant. The first time a given transition state is the highest,
the connection attempt is between the adjacent minimum.
The next time it is chosen we use the second-nearest neighbours along the path in question.
The parameter {\it n1} determines how many steps away from the transition state we
continue these connection attempts for. The default is {\it n1}=1.
Once {\it n1\/} attempts have been tried for the highest transition state we
move to the second-highest, and so on.
Minima with {\it n2} connections or fewer are iteratively removed before the network
analysis. The default value for {\it n2} is one.
The {\it string\/} argument, which is optional, only has an effect if it is the
word `BARRIER'. In this case the pairs of minima to connect are sorted according to the 
largest barrier 
that separates them. Otherwise they are sorted in order of increasing
energy of the minimum that is separated from the product region.

\item {\it DIJPRUNE exp or n max p1 p2\/}: using the existing best path calculation
in {\it DIJINITCONT\/} it creates a new file {\tt min.retain} which only contains minima
on the best path. The weighting option are identical to {\it DIJINITCONT\/}. It requires
that {\it CYCLES\/} is set to 1.
Allows consequently to remove all other minima (useful to keep databases small). Can be used
with {\it PRUNECYCLE} and {\it IGNOREPAIRS}.

\item {\it DIRECTION a\/}: the direction (`AB' or `BA') determines the sense of a path, for 
contexts where forward and backward or reactant and product need to be defined. Note the use 
of the spectroscopists' convention, whereby `AB' means from B to A . The default is `AB'. 

\item {\it DSCALE x\/}: specifies how the separation between local minima, {\it d}, is used
to select the pair used in the next attempted connection. If
$\exp(-(d-x)/x) < $ a random number drawn from $[0,1]$ then the distance criterion is accepted.
There is also a criterion for the difference in committor probabilities (see {\it PSCALE}).
If $d<x$ then the distance criterion is always satisfied; above $x$ the probability
of acceptance decreases exponentially.

\item {\it DUMMYRUN\/}: specifies that no {\tt OPTIM} jobs should be submitted; the program just
sleeps instead.

\item {\it DUMMYTS\/}: specifies that dummy transition state entries should be created for
selected pairs of minima. The corresponding database of minima and dummy transition states
can be refined using any of the usual schemes, e.g.~{\it SHORTCUT\/}, {\it FREEPAIRS\/}, etc.
Either {\it BHINTERP\/} or {\it BISECT\/} needs to be specified in the {\tt pathdata} file,
so that {\tt OPTIM} jobs only locate new local minima and feed them to {\tt PATHSAMPLE}
via {\tt min.data.info} files.
The dummy entries in {\tt ts.data} include connections for all nearest pairs of minima
for {\it BHINTERP\/}, but only for successive pairs of minima with {\it BISECT\/}.
The dummy energy and log product of mass-weighted Hessian eigenvalues for each
{\tt ts.data} entry are chosen according to properties of the two minima.
The current energy estimate is the energy of the higher minimum plus the minimum distance
between the two minima.
The estimate for the log product of eigenvalues simply rescales the value for the higher minimum,
effectively removing one degree of freedom.
At some point a decision must be made to start linking the minima via genuine transition
states. To do this we use {\it USEPAIRS}, which reads a sequence of stationary points in
the format of the {\tt Epath} file.
The dummy {\tt ts.data} and {\tt pairs.data} files must be renamed or removed.

\item {\it DUMPGROUPS\/}: specifies that the groups of potential energy minima and transition
states corresponding to groups of free energy minima and transition states should be dumped
to files {\tt minima\_groups} and {\tt ts\_groups} following regrouping.

\item {\it EDIFFTOL x\/}: two stationary points will only be identified as the
same structure if their energy difference is less than {\it x} and their minimum
distance is less than the threshold specified by {\it GEOMDIFFTOL\/}.
{\it ETOL\/} specifies the same parameter and is provided for backward compatibility.

\item {\it ENERGY x\/}: specifies that the microcanonical ensemble at energy {\it x\/} is to be used
to calculate rate constants. Mutually exclusive with {\it TEMPERATURE\/}.

\item {\it ETOL x\/}: energy difference criterion for distinguishing stationary points. 
Used with {\it ITOL\/} in {\tt PATHSAMPLE.2.0\/} and {\it GEOMDIFFTOL\/} in
{\tt PATHSAMPLE.2.1\/}. {\it EDIFFTOL\/} specifies the same parameter.

\item {\it EVCUT x\/}: tolerance for Hessian eigenvalues or frequencies read from
a {\tt path.info} file by the {\bf getallpaths} subroutine.
If an eigenvalue is detected that should belong to the positive set by lies below
{\it x\/} (default value $2\times10^{-6}$) the min-sad-min triple is skipped.

\item {\it EXEC a\/}: name of the {\tt OPTIM} executable to be called by {\tt PATHSAMPLE}.

\item {\it EXTRACTMIN n\/}: extract the coordinates of minimum {\it n} from
{\tt points.min} and write them to file {\tt extractedmin}. If the {\it CHARMM}
keyword is present then a pdb format {\tt extractedmin.pdb} will also be
produced. If $n\le0$ then all the minima are extracted to {\tt extractmin}.

\item {\it EXTRACTMINFILE\/}: extract the coordinates of minima 
listed in file {\tt extractmin} from
{\tt points.min} and write them to file {\tt extractedmin}. 

\item {\it EXTRACTTS n\/}: extract the coordinates of minimum {\it n} from
{\tt points.ts} and write them to file {\tt extractts}.
If the {\it CHARMM}
keyword is present then a pdb format {\tt extractedts.pdb} will also be
produced. If $n\le0$ then all the transition states are extracted to {\tt extractts}.

\item {\it FROMLOWEST (NOLABELS)}: reads GMIN {\tt lowest} files and writes PATHSAMPLE {\tt points.min}
and {\tt min.data} files. Frequencies are not currently calculated, and so {\it FROMLOWEST}
can only be used when {\it NOFRQS} is specified. If you GMIN lowest file does NOT contain atom labels
at the start of each line, the NOLABELS option should be used.

\item {\it FREEPAIRS x1 x2 x3\/}: connection pairs are chosen based upon the same free energy
regrouping scheme as {\it REGROUPFREE\/}.
{\it x1} corresponds to the free energy barrier height below which free energy
minima are combined.
Free energy minima that lie more than {\it x2} units of energy above the global
free energy minimum group are ignored.
{\it x3} is the energy increment used in the superbasin analysis to estimate 
barriers.
Pairs of potential energy minima are chosen from groups based on the ratio
of free energy barrier height to product divided by free energy difference
from product. Hence we highlight groups that correspond to {\it frustration\/},
with similar energies to the product but high barriers.
Local minima from these free energy groups are then chosen
based upon an additional shortest distance criterion. 
Searches are not repeated for the same potential energy minima.
{\bf NOTE}: for this to work efficiently it is important to have the lowest
minima specified in {\tt min.A} and {\it DIRECTION\/} set to AB, so that
the A minima are product, and lie at the bottom of the landscape.
See also the {\it PAIRLIST\/} keyword.

\item {\it FREEZE n1 n1\ldots\/}: specifies that atoms $n1$, $n2\ldots$, should be frozen.
This keyword must come after the {\it NATOMS\/} keyword.

\item {\it FRICTION $\gamma$\/}: specifies that rate constants should be 
calculated using the multi-dimensional version of Kramer's theory described by
Berezhkovskii, Pollak and Zitserman.\cite{BerezhkovskiiPZ92}
$\gamma$ is a phenomenological `friction' coefficient in frequency units, which
must correspond to the units for the Hessian eigenvalue product in the
{\tt ts.data} file. This formulation requires the imaginary normal mode
frequency for each transition state, and the {\tt ts.data} file must therefore
contain a ninth column corresponding to the unique negative Hessian eigenvalue.
For the {\it CHARMM\/} and {\it AMBER\/} force fields this eigenvalue is the
angular frequency squared in SI units, while for all other potentials it will
be in reduced units. Such databases can be extended without using the `friction'
formulation by setting the {\it IMFRQ\/} keyword (or by using $\gamma=0$).

\item {\it GEOMDIFFTOL x\/}: two stationary points will only be identified as the
same structure if their minimum separation is less than {\it x} and their energy
difference is less than the threshold specified by {\it EDIFFTOL\/}.

\item {\it GETMINFRQS \/}: used with {\it CHECKMIN}. For all checked minima the {\tt frqs.dump} file
is created and then all frequencies are written to a new file {\tt frqs.min}. 
Every frequency is paired with the minimum id, and it can then be used to create a {\tt min.data} file 
with frequencies, if OPTIM and PATHSAMPLE were run with {\it NOFRQS}.
Frequencies are only written, if the {\it CHECKMIN} routine converged. The {\tt odata.checksp} file
needs to contain {\it DUMPFRQS}.

\item {\it GETTSFRQS \/}: used with {\it CHECKTS}. For all checked minima the {\tt frqs.dump} file
is created and then all frequencies are written to a new file {\tt frqs.ts}. 
Every frequency is paired with the minimum id, and it can then be used to create a {\tt ts.data} file 
with frequencies, if OPTIM and PATHSAMPLE were run with {\it NOFRQS}.
Frequencies are only written, if the {\it CHECKTS} routine converged. The {\tt odata.checksp} file    
needs to contain {\it DUMPFRQS}.  

\item {\it GT n1 n2\/}: specifies that the graph transformation approach\cite{TrygubenkoW06}
should be used to calculate rate constants. 
Minima with {\it n1} connections or fewer are iteratively removed before the rate
calculation. {\it n2} specifies that the rates should be calculated every {\it n2} cycles
during the refinement of the stationary point database. For large databases making {\it n2} equal to one
could slow the sampling down significantly.
To run a GT calculation without changing the stationary point database set {\it CYCLES 0}.
See keyword {\it GT2\/} for a more general implementation of graph transformation.
The rates produced from the {\it GT} keyword correspond approximately to the
$k^{\rm NSS}$ rate constants \cite{TrygubenkoW06,Wales06}.
Branching probabilities for return to the same initial state are set to zero,
and all the other connections are renormalised accordingly. Hence the final branching
probabilities for a given source include arbitrary revisits to that source before 
a path reaches a different source or a product, so they do not quite correspond to 
committor probabilities. In practice, the resulting rate constants generally seem to
be close to the $k^{\rm NSS}$ values.

\item {\it GT2 } This keyword has been removed. Please use {\it SGT},
{\it DGT} or {\it SDGT}.

\item {\it GT2RSwitch x \/}: specifies that the generalised graph transformation
routines switch from single to double precision when the density reaches {\it x\/}.
The default value is $x=0.08$.
See keyword {\it SDGT\/} and subroutine {\bf GT2} for more information. 

\item {\it GT2PTOL x\/}: specifies the threshold for deciding that a node is dead
in the generalised graph transformation routines. The default value is $x=0.00001$.

\item {\it IGNOREPAIRS value \/}: value is either TRUE or FALSE. If set to TRUE, previously
searched pairs will be ignored in the Dijkstra analysis in the Dijinit subroutine.

\item {\it IMFRQ\/}: specifies that the {\tt ts.data} file should contain a ninth 
column containing the unique negative Hessian eigenvalue. This
is the eigenvalue corresponding to the imaginary normal mode frequency.
See also the {\it FRICTION\/} keyword, which implies the same format for
{\tt ts.data} and calculates the rate constants using a phenomenological
description of dynamical solvent friction.

\item {\it INITIALDISTANCE disbound\/}: use a fictitious fixed distance {\it disbound} for pairs of minima
in {\it DIJINITSTART\/} and {\it DIJINITCONT} runs.
The true distance is only calculated when the connection appears in the Dijkstra missing connection
best path, and the Dijkstra analysis is repeated until all the steps in the best path involve connected minima
or pairs where the true distance is known.
With a small {\it disbound}  we calculate all the true distances, because the small distance makes it into the best path. 
With a large {\it disbound}  we will accept larger true distances into the best path, so fewer distance calculations will be needed.
The objective is to stop pair distance calculations from slowing down initial pathway attempts,
where a large number of permutable groups can be a problem, especially for {\it LPERMDIST\/}.
The current distance values are saved in file {\tt allpairs} and held in memory in vector ALLPAIRS.
If a database grows very large without an initial connection being found, this vector may cease to
fit in available memory.
The algorithm is similar to the one presented by Noe et al.~JCTC, {\bf 2}, 840, 2006. 
If {\it disbound\/} is negative then all distances are calculated.

\item{\it INTCONSTRAINT intconstrainttol intconstraintdel intconstraintrep intconstrainrepcut
intconsep intrepsep \/} 
specifies quasi-continuous interpolation via an auxiliary constraint potential, as
for {\tt OPTIM}. Note that some of the {\tt OPTIM} parameters are not needed
for {\tt PATHSAMPLE}, and are omitted.
In {\tt PATHSAMPLE} this keyword is only used to define the QCI metric, which can
be used in selecting minima for connection. It is never used with any intervening
images. {\tt PATHSAMPLE} does not use {\tt congeom} or {\tt congeom.dat} files:
it simply calculated the QCI metric based on pairs of local minima.
{\it intconstrainttol\/} is used to determine constrained distances. The deviation
of the distance between a given pair of atoms 
in all reference structures from the average must be less than
{\it intconstrainttol\/}, default 0.1, for this separation to constitute a constraint.
If a percolating network of constraints does not result then {\it intconstrainttol\/}
is increased by 10\% and the analysis repeated.
{\it intconstraintdel\/} multiplies the constraint penalty term in the auxiliary potential,
default 10.0.
{\it intconstraintrep\/} multiplies the repulsive penalty term in the auxiliary potential,
default 100.0.
{\it intconstrainrepcut\/} is the cutoff for the repulsive penalty term in the auxiliary potential,
default 1.7.
{\it intconsep\/} is the maximum difference between the order number of atoms for
which constraints are allowed. The default is 15, which seems appropriate for 
biomolecules. However, if a {\tt congeom} file of reference minima is specified, or
a corresponding {\tt congeom.dat} file is present, then {\it intconsep\/} can be set
greater than the total number of atoms.
{\it intrepsep} is the minimum difference in order number of atoms for which repulsive
terms are added to the potential. The default is zero; there are no repulsive terms
between constrained atoms.

\item {\it ITOL x\/}: principal moment of inertia tensor difference criterion for 
distinguishing stationary points. All three values are compared for stationary points
in the initial setup phase. However, unlike {\tt PATHSAMPLE.2.0}, the alternative
criterion specified by {\it GEOMDIFFTOL\/} is used to distinguish stationary points
in {\tt PATHSAMPLE.2.1}.

\item {\it JOBSPERNODE jpn\/}: WARNING This keyword is now deprecated and any jobs that include it 
will stop with an error message. It specified the number of jobs to run on each core for a
calculation using a scheduler such as PBS to send jobs to distributed nodes. The cores 
must be defined by the job submission script in the {\tt nodes.info} file.
The keyword is not called {\tt JOBSPERCORE} for historical reasons and backward compatibility.
Unless you really want to run more than one job per available core at one time then
{\it jpn} can be omitted: the default value is one. The {\it PBS} keyword should
probably be used instead of {\it JOBSPERNODE} going forward. 

\item {\it KMC n1 x n2\/}: perform {\it n1} KMC runs having iteratively removed
minima with {\it n2} connections or fewer.
{\it x} specifies a pair threshold for the product, {\it p}, of forward and backward
branching probabilities between two minima.
If {\it p} is greater than {\it x} then a leapfrog move will be attempted to a
different connected minimum when either of the pair is encountered.
Setting {\it p} to one or more means that leapfrog moves will not be used.
No additional stationary points will be calculated in a {\it KMC}
run: the {\it CYCLES} keyword is ignored if it is present in {\tt odata}.
Only one of the {\it GT}, {\it GT2}, {\it KMC} and {\it KMCcommit} keywords should be
present in a given {\tt pathdata} file.

\item {\it KMCcommit n1 x1 x2 x3 x4 n2}: specifies a rate constant calculation using
committor probabilities and appropriate waiting times. This subroutine can calculate 
both `SS' and `NSS'-type rate constants.\cite{TrygubenkoW06}
{\it n1} is the number of KMC trajectories to run. If {\it n1} is zero then
the waiting time in a given minimum is the the escape time
to its connected neighbours. Combined with the committor probabilities,
these waiting times give `SS' rate constants. If {\it n1} is greater than zero then
the waiting times are calculated for KMC runs that terminate as soon as they reach
a minimum in either the A or the B region. The resulting rate constants
are described as `NSS'.\cite{TrygubenkoW06}
{\it x1} is the maximum number of iterations allowed in the committor probability
calculation; it is a real number because the value required may exceed the size allowed
for an integer.
{\it x2} is a convergence condition for the committor probabilities, and is defined
in terms of the percentage change between iterations.
{\it x3} is the $\omega$ parameter used in the successive overrelaxation calculation
of the committor probabilities. It should be greater than or equal to one, but less than 2.
The default value is one, which results in Gauss-Seidel iterations.
{\it x4} specifies a pair threshold for the product, {\it p}, of forward and backward
branching probabilities between two minima.
If {\it p} is greater than {\it x} then a leapfrog move will be attempted to a
different connected minimum when either of the pair is encountered.
Setting {\it p} to one or more means that leapfrog moves will not be used.
{\it n2} determines the minimum connectivity allowed for local minima to be
admitted into the calculation. The minima are iteratively pruned to remove those
with {\it n2} connections or fewer.
No additional stationary points will be calculated in a {\it KMCcommit}
run: the {\it CYCLES} keyword is ignored if it is present in {\tt odata}.
Only one of the {\it GT}, {\it GT2}, {\it KMC} and {\it KMCcommit} keywords should be
present in a given {\tt pathdata} file.

\item {\it KSHORTESTPATHS npaths nconnmin extraprinting\/}: calculate the {\it npaths\/} paths
with the largest contributions to the rate constant when intervening minima are
put in steady state. Coded by Dr Joanne Carr. 
{\it nconnmin\/} specifies that minima with {\it nconnmin} connections or fewer
should be disregarded in this analysis. Setting the optional argument {\it extraprinting} to "T" 
turns on extra output printing for each path (off by default). 

\item {\it LOCALPERMDIST thresh cutoff\/}: minimise distances between end points
prior to DNEB interpolation using local alignment.
{\it thresh} is used to define the tolerance for a `perfect' alignment
in routine {\bf minpermdist}, which is called for subsets of atoms
rather than all at the same time for {\it PERMDIST}.
The threshold used is actually the number of atoms in the permutable
group in question times {\it thresh\/}.
The routine {\bf minpermrb} cycles through the permutable groups,
calling {\bf minpermdist} for each one, augmented by any other permutable
groups that overlap, as for any groups with additional pair swaps, such
as valine and arginine.
Atoms that are equidistant from the permutable atoms in the two end points
are also added to the set if the distance lies within a cutoff
radius {\it cutoff\/}.
They are added in increasing distance order, and removed one at a time
if the resulting subsets of atoms cannot be aligned `perfectly' between
the two endpoints.
Using cutoffs of 2.5 and 5\,\AA\ gives different internal rotations for
an arginine group, but with similar barriers.
The default values are 0.1 and 5.0 for {\it thresh} and {\it cutoff\/},
respectively.
Requires the auxiliary file {\tt perm.allow} to specify permutable atoms, otherwise
all atoms are assumed to be permutable. The absence of a {\tt perm.allow}
file is considered a mistake for {\it CHARMM\/} runs.
See also {\it LPERMDIST\/}, which effectively replaces {\it LOCALPERMDIST\/}.

\item {\it LOWESTFRQ\/}: specifies that the lowest positive eigenvalues associated
with the Hessian and mass-weighted Hessian should be read from {\tt min.data.info\/}
files and recorded in {\tt min.data}.
These eigenvalues can then be used in combination with {\it DUMMYTS\/}
to estimate the energy and frequency factor associated with dummy transition states.
The {\it LOWESTFRQ\/} keyword must also appear in {\tt odata.bhinterp} or {\tt odata.bisect}.
The current estimate for dummy transition state parameters does not require these
extra data.

\item {\it LPERMDIST n thresh cut orbittol\/}: provides the preferred local
permutational alignment procedure.
{\it PERMDIST\/} may be a better option for large biomolecules until the
database actually contains a connection (see end of paragraph).
{\it n\/} is the maximum number of extra atoms to include in running
{\bf minperm\/} for each permutable group (default 4), rather than
treating the whole system at the same time, as for {\it PERMDIST}.
The extra atoms that define the neighbourhood of the permutable group are
added one at a time in order of their distance from the centre of coordinates of the
group, averaged over the start and finish geometries.
If the optimal aligned distance is greater than {\it thresh\/} (default value 0.2)
then the atom is not included in the neighbour list.
This procedure continues until there are {\it n\/} atoms in the neighbour list,
or no more atoms within the cutoff distance {\it cut\/}, default 10.0.
The parameter {\it orbittol} is the distance tolerance for assigning atoms to orbits
in the {\bf myorient} standard orientation routine, default value 0.001.
This keyword requires the auxiliary file {\tt perm.allow} to specify permutable atoms, otherwise
all atoms are assumed to be permutable. The absence of a {\tt perm.allow}
file is considered a mistake for {\it CHARMM\/} runs.
WARNING: {\it LPERMDIST\/} can slow down {\it DIJINITCONT\/} runs dramatically
for large biomolecules with many permutable groups if the database grows beyond a
thousand minima without finding an iniial connection.
In fact, {\it PERMDIST\/} in the {\tt pathdata} file may be OK (and much faster)
so long as {\it LPERMDIST\/} is used for {\tt OPTIM}, which would fix any
bad permutational alignments before starting a transition state search.

\item {\it MACHINE\/}: if specified, certain files are written and read as
binary rather than plain text.

\item {\it MACROCYCLE n\/}: sets up permutational isomers for a
macrocyclic system. The number of repeat units in the macrocycle is given by
{\it n} (e.g. {\it n}=4 for cyclo-[Gly$_4$]). The order of the atoms in
each repeat unit must be the same and these permutations should not be added to
the {\tt perm.allow} file. This keyword has only been tested on cyclic peptides using
the AMBER potential.

\item {\it MAKEPAIRS pairfile\/}: use in conjunction with ADDMIN or READMIN
to produce an {\tt Epath}-style pairfile which can then be used with USEPAIRS
to connect a chain of minima together. The minima from the min.data.info are
read into the PATHSAMPLE database as normal, but in addition the pairfile
records the indices of the minima in the order in which they appeared in
min.data.info. Running PATHSAMPLE with USEPAIRS then connects every pair of
minima from the original min.data.info file, in the order they appeared. Minima
may appear multiple times in the same pairfile if they appear multiple times in
min.data.info. The exception is consecutive duplicate minima, which are
omitted.

\item {\it MAXBARRIER x\/}: use in the post-processing analyses to set a criterion for excluding transition 
states if the barriers from both connected minima exceed {\it x\/}. The threshold {\it x\/} is reset to infinity 
on converting potential energies to free energies during a run.

\item {\it MAXDOWNBARRIER x\/}: specifies a maximum downhill barrier 
of {\it x\/} for {\it DIJKSTRA\/} analysis. 
The downhill barriers for the path with the largest contribution to the
non-recrossing steady-state rate constant are sorted and those that exceed
{\it x\/} are analysed further. The transition state in question is removed
and the {\it DIJKSTRA\/} analysis performed again if a connected path is still possible.
If a connected path is no longer possible the transition state in question is
reinstated. A list of `shiftable' transition states is provided at the end.
Note that the order in which transition states are removed could affect this list,
so that other combinations of `shiftable' transition states may be possible.
The downhill direction can only be defined locally once the complete
{\it DIJKSTRA\/} path is known, since `downhill' is determined by the energies
of the two endpoints.

\item {\it MAXTSENERGY x\/}: specifies that transition states above energy $x$ should
not be included in the database. Probably most useful with CHARMM, where genuine 
transition states with silly energies can certainly occur and give rise to underflow.
This keyword performs the same function as {\it TSTHRESH\/}, and is provided because
{\tt OPTIM} uses {\it MAXTSENERGY\/}.

\item {\it MERGEDB dir\/}: merge the {\tt min.data}, {\tt min.ts}, {\tt points.min},
{\tt points.ts}, {\tt min.A} and {\tt min.B} files from directory {\it dir} with
those in the current directory. Common stationary points are identified and
not repeated. Merged results are created corresponding to all six of the above files.

\item {\it MINBARRIER x\/}: use in the post-processing analyses to set a criterion for excluding a transition 
state if the barrier in either direction is lower than {\it x\/}. Designed to allow exclusion of TSs 
present in the database that lie lower in potential energy than the connected minima, by setting {\it x\/} to zero. 
The default value is (basically) minus infinity. Note that a transition state may legitimately lie lower 
than the connected minima in free energy.

\item {\it MINGAP x RATIO\/}: sets a cut off for what connections should be tried in a Dijinit run.
Either {\it x} is the minimum distance between two minima for a connection run to be started, or if RATIO
is used, x is the fraction of the maximum pair distance that is then used as minimum. Should be used to 
focus searches on large gaps in the database and ignore small connections entirely.


\item {\it MLPB3} specifies a multi-layer perceptron neural network
with {\it in} input nodes, {\it hidden} hidden nodes, {\it out} output nodes, regularisation constant
$\lambda$ and bias nodes for the hidden and output sums.
The number of variables is {\it hidden}$\times$(in+out)+1,
and {\tt PATHSAMPLE} needs this keyword to deal with input/output
for the {\tt OPTIM} {\it VARIABLES} format. There is another keyword
{\it MLP3}, which is exactly the same without the bias nodes.

\item {\it NATOMS n\/}: the number of atoms in the system; must be present.

\item {\it NCONNMIN n\/}: specifies that minima with {\it n} connections or fewer
should be disregarded in regrouping and rate calculations. This parameter
can be set via other keywords, but {\it NCONNMIN} is provided for use with
{\it SGT}, {\it DGT}, {\it SDGT} and also {\it PFOLD}. The connection condition is evaluated recursively.

\item {\it NEWCONNECTIONS n maxattempts firstmin\/}: 
this keyword provides a fully parallelised way to grow a database using single-ended
transition state searches.
It therefore provides an alternative to procedures such as {\it SHORTCUT\/} and
{\it UNTRAP\/}.
Starting from {\it firstmin\/} (default 1) PATHSAMPLE will step through all the
known minima and perform up to {\it maxattempts} transition state and pathway
searches (default 10) according to the template {\tt odata.tspath} file, which must be
present in the working directory.
The next minimum will be considered if the current minimum has
{\it n} or more connections (default 0).
for which the default is 10.
The {\tt odata.tspath} file needs to contain OPTIM {\it PATH} 
and {\it DUMPALLPATHS\/} directives
so that a {\tt path.info} file is created.

\item {\it NGT nconnmin disconnectsources density size compressedrowswitch\/}: specifies that the new
graph transformation approach should be used to calculate rate constants. 
Minima with {\it nconnmin} connections or fewer are iteratively removed before the rate calculation. 
This calculation produces $k^{\rm SS}$, $k^{\rm NSS}$ and $k^{\rm KMC}$ for both 
$A\leftarrow B$ and $B\leftarrow A$, as well as committor probabilities.
If {\it disconnectsources} is true (default is false) then $k^{\rm KMC}$ is also
calculated. For single sources $k^{\rm KMC}$ is the same as $k^{\rm NSS}$.
The algorithm switches from sparse to dense storage when the number of connections
exceeds {\it density} times the maximum possible value, with the restriction that
there must be {\it size} minima or fewer remaining. The default values for {\it density}
and {\it size} are 0.3 and 11000.  Within the initial sparse storage scheme, the algorithm will use
compressed row (vector) storage instead of full, rectangular matrix storage if the memory required for the 
two rectangular matrices at the start of the NGT calculation would exceed {\it compressedrowswitch\/} Gb.
See also keyword {\it GT2\/} for the original graph transformation calculation of $k^{\rm KMC}$.
The committor probabilities for the end point minima, which are obtained on removing all the 
intervening minima, are written to two files: commit.ngt.AB for direction B to A and commit.ngt.BA for the opposite 
direction.  The entries for the intervening minima are zeroes.  These files have the same form and ordering as commit.data.
The {\it PFOLD} keyword (see below) may be given in addition to {\it NGT}, in which case a commmittor probability
calculation using the specified control parameters will immediately follow the NGT calculation, and
will be seeded with the known (and fixed) committor probabilities from NGT for the end point minima.
A file commit.data, with one entry for each minimum in the pre-resorting order, will be written at the 
end of this calculation containing the committor probabilities for the direction specified via {\it DIRECTION}.

\item {\it NINTS n\/}: the number of internal coordinates; required for runs 
with the UNRES potential. 

\item {\it NIMET NIHEAM7 \/}: these keywords ensure that the EAM4 and EAM7 potentials for hydrogen on a nickel surface
(see OPTIM manual for more details) get the right atom symbols when called from pathsample.

\item {\it NOFRQS\/}: specifies that frequencies are not present in {\tt path.info} files.
Used for very large systems where frequency calculations are not feasible in conjunction
with the same {\tt OPTIM} keyword.
The log product of positive eigenvalues is set to unity where it is read in from
{\tt ts.data} and {\tt min.data} in {\bf setup} and {\bf Dijsktra} for consistency.

\item {\it NOINVERSION\/}: turns off inversion of structures for distance
metric in {\bf minpermdist}.

\item {\it NOTRANSROT\/}: forbid overall translation/rotation in alignment and distance
calculations.

\item {\it NTIP  4\/}: calls the TIP4P model of water molecules.

\item {\it OHCELL \/}: allow point group operations for a cubic
supercell in subroutine {\tt minpermdist.f90} permutational distance minimisation.

\item {\it ORBITGEOMTOL x\/}: sets the cutoff value for assigning atoms to the
same orbit when analysing the standard orientation in routine {\bf myorient}
when {\it LPERMDIST\/} is specified.
The default value for {\it x\/} is 0.3.
If {\it x} is too small it is possible for permutational isomers to be missed.

\item {\it ORDER x\/}: reads in an order parameter threshold. Currently not used.

\item {\it PAHA n\/}: calls a finite system of polycyclic aromatic hydrocarbons (PAH) interacting
via a general anisotropic potential developed from first principles \cite{TottonMK10}. The PAH ID
{\it n} defines the PAH molecule: 1 for benzene is the only option currently available.

\item {\it PAIRLIST n\/}: specifies that the list of minima for subsequent connection attempts
should be regenerated every {\it n\/} cycles. The default is for the list to remain
fixed throughout the run unless we run out of candidates. This option has been 
implemented for the {\it FREEPAIRS\/}, {\it SHORTCUT\/}, {\it UNTRAP\/} and
{\it DIJPAIR} keywords and for the default connection
strategy based on differences in the committor probability. It has not been 
implemented for the {\it CONNECTREGION\/} keyword.

\item {\it PBS jpn\/}: specifies the number of jobs to run on each core for a
calculation using a scheduler such as PBS to run {\tt OPTIM} jobs on
distributed nodes. The cores 
must be defined by the job submission script in the {\tt nodes.info} file.
Unless you really want to run more than one job per available core at a time then
{\it jpn} can be omitted: the default value is one. 

\item {\it PERMDIST x\/}: specifies that all distance metrics should include minimisation
with respect to permutational isomerisation, as well as optimal orientation.
Should be used with the same keyword in {\tt OPTIM}.
Requires the auxiliary file {\tt perm.allow} to specify permutable atoms.
The first line of the {\tt perm.allow} file must contain an integer
that specifies the number of primary groups of interchangeable atoms.
The groups then follow, each one introduced by a line with two integers $p$ and $s$
that specify the number of permutable atoms in the primary group and the number of other sets
of permutable atoms associated with the primary set.
$s$ may be zero.
Each secondary set of permutable atoms has $p$ members.
The following line contains the indices of the $p$ permutable atoms 
in the primary set and then
the indices of the atoms in each of the $s$ secondary sets, one set at 
a time.
The parameter {\it x} is the distance tolerance for assigning atoms to orbits
in the {\bf myorient} standard orientation routine.
If {\it x} is too small it is possible for permutational isomers to be missed.

\begin{figure}[h]
\centerline{\includegraphics[width=0.5\textwidth]{PHE.eps}}
\end{figure}

For the phenylalanine example illustrated above we must allow three other pairs of
atoms to exchange if we swap 7 and 8. Hence a suitable {\tt perm.allow} entry is
{\obeylines
1
2 3
7 8 5 6 1 2 3 4
}
Here $n=2$ and $s=3$: if we exchange 7 and 8 then we must also exchange 5 and 6,
1 and 2, and 3 and 4. There are two atoms in each of the three secondary sets, 
since we have specified 7 and 8 as the two primary atoms.

Here is an example {\tt perm.allow} file for a water trimer using
the flexible {\it QTIP4PF\/} potential, where the energy is invariant to permutations
of water molecules and to exchanges of hydrogens in the same molecule. However,
hydrogens cannot exchange between different oxygens:
{\obeylines
4
3 2
1 4 7 2 3 5 6 8 9
2 0 
2 3
2 0 
5 6
2 0 
8 9
}
The first group of three oxygens has two atoms that must move with each oxygen,
i.e.~atoms 2 and 3 for oxygen 1, etc. Hydrogen permutations for each oxygen are
allowed by the three following groups. This scheme allows atoms to appear in more 
than one group. There must be a group containing each complete set of permutations
in order for permutation-inversion isomers to be recognised. The format
is compatible with an older scheme, where only pair swaps were allowed for
associated atoms, but now allows for more general permutations.

Scripts to generate allowed permutations automatically for CHARMM and AMBER are available from
the group web site. It is essential to use symmetrised versions of the corresponding
force fields! 

\item {\it PERMISOMER\/}: equivalent to {\it PERMDIST\/} above, expect that
distance minimisation 
with respect to permutational isomerisation is only carried out for stationary
points with energies that differ by less than the parameter specified by {\it EDIFFTOL}.
Hence permutational isomers should be identified, but the distance between minima with
different energies is not minimised with respect to atom permutations.
This option is provided for cases where the number of permutations is too 
minimise distances with respect to permutations in general.
Should be used with the {\it PERMDIST\/} keyword in {\tt OPTIM}.
The auxiliary file {\tt perm.allow} specifies which atoms may be permuted; see
{\it PERMDIST\/} above.
Note that the {\it NATOMS\/} keyword must precede {\it PERMISOMER\/} in the
{\tt pathdata} file.

\item {\it PERSIST einc pethresh peqthresh perthresh \/}: 
Persistence analysis along the lines of Cazals et al.
We perform a persistence analysis using superbasins at energy increments of {\it einc}
up to a maximum energy range of {\it pethresh}.
This analysis uses the persistence for each minimum, defined as the barrier to the transition state
where that minimum can access a lower-energy minimum.
Output files are {\tt min.persist}, {\tt min.persist.select} and {\tt min.include}. The latter two 
include only some of the most persistent minima, selected based on a lower bound 
equilibrium occupation probability {\it peqthresh} and a lower bound, {\it perthresh}, on the barrier 
height defined by the persistence (actually the deviation from the diagonal in a
persistence diagram, which is the same aside from a factor of $\sqrt{2}$). The usual criteria for transition 
states and the connectivity of minima also apply.
The file {\tt min.include} has a format suitable for reading via the
{\it PICK} and {\it IDMINFILE} keywords in {\tt disconnectionDPS}. The format of the {\tt min.persist*} files 
is: {\it rank (ordered by persistence), energy, energy+barrier, barrier(=persistence), index of the minimum, 
deviation from the diagonal}. See also {\it PERSISTEXACT\/}

\item {\it PERSISTEXACT ALL\/}: 
For use with {\it PERSIST\/}; specifies that the barrier heights used to define the persistences 
should be obtained via an efficient exact method, rather than the approximate method using 
a superbasin analysis. Note that the values of {\it einc} and {\it pethresh} from {\it PERSIST\/} are not 
used here, but must still be present if you want to specify values for {\it peqthresh} and {\it perthresh}. 
The optional argument {\it ALL} instructs the program to report persistences for 
all the valid minima in the network; the default is to report values only for the minima in the same connected 
component as the global minimum (which matches the situation for the approximate method).

\item {\it PERTURB x\/}: initial maximum perturbation of the Cartesian coordinates of a minimum, 
when looking for a new connected minimum via a single-ended transition state search.

\item {\it PFOLD n1 n2 x PFOLDCONV\/}: provides control parameters for the calculation
of committor probabilities for local minima.  The calculation
may be performed on-the-fly during the construction of a stationary point database (if used together 
with CYCLES <non-zero value>) or as a post-processing analysis (CYCLES 0).
All new local minima are assigned an initial value of zero.
If a file commit.data exists in the working directory then initial values at the start of the run 
will be taken from there.
{\it n1} iterations are performed every {\it n2} cycles with parameter $\omega$ in
the successive overrelaxation equal to {\it x}.
PFOLDCONV is the threshold on the largest fractional difference between Pfold values at 
consecutive iterations for early convergence of the algorithm (before the full {\it n1} iterations 
have been performed).  The default value is 0.0001.
Note that a valid solution also exists for all committor probabilities equal to unity.
I have seen the iteration converge to this solution for a  very small database that
has just been created with {\it DIJINIT\/}. 
A file commit.data, with one entry for each minimum under consideration in the pre-resorting order, 
will be written at the end of a 
committor probability calculation for the pathway direction specified in {\it DIRECTION}.
The {\it PFOLD} keyword may be given in addition to {\it NGT}, in which case a commmittor probability 
calculation using the specified control parameters will immediately follow the NGT calculation, and 
will be seeded with the known (and fixed) committor probabilities from NGT for the end point minima.

\item {\it PLANCK h\/}: specifies the value of Planck's constant in units of the
prevailing energy unit times seconds. This numerical value is required for 
regrouping free energies. For example, for the {\it CHARMM} potential $h$ needs
to be $9.546\times10^{-14}\,$s\,kcal/mol
See \S \ref{sec:units} for more details.

\item {\it PRINTSUMMARY}: prints (to standard out) some information about the kinetic transition 
network, including the number of minima and transition states satisfying the various thresholds, the highest 
and lowest TSs, and some information about the connected components present. The analysis is performed 
after the SETUP routine has been passed through.

\item {\it PRUNECYCLE n\/}: repeats the Dijkstra analysis for {\it DIJPRUNE} {\it n} times and records all minima, on the so found n
fastest paths (all missing connections can be used once overall). Default is 5 cycles.

\item {\it PULL \/}: add this keyword if the system has a non-zero static force 
added to the potential. {\tt PATHSAMPLE.2.1} only uses this keyword to determine the
number of zero Hessian eigenvalues (four). The attached atoms and force magnitude
are not required.

\item {\it PSCALE x\/}: determines how the difference in committor probabilities,
$p$, is used to select the pair of minima used in the next attempted connection. If
$p/x > $ a random number drawn from $[0,1]$ then the distance criterion is accepted.
There is also a criterion for the minimum distance (see {\it DSCALE}).
If $p>x$ then the committor probability criterion is always satisfied; below $x$ the probability
of acceptance decreases linearly.

\item {\it RANDOMMETRIC n\/}: for {\it DIJINITCONT\/} jobs this keyword limits
the number of metric calculations for each new minimum to {\it n}. The {\it n} 
other minima are chosen randomly. The cost of adding each new minimum to the 
database is therefore constant, rather than growing linearly with the number
of minima in the database. If {\it n} is less than the {\it max}
parameter for {\it DIJINITCONT\/} then the metric values are padded with
enormous values.

\item {\it RANROT n\/}: for use with {\it PERMDIST\/}. Specifies
that {\it n\/} random orientations will be tried as well as the
initial standard alignment in {\tt minpermdist.f90}. Several hundred
random orientations may be needed to find the best translational/rotational/permutational
alignment of end points.

\item {\it RATESCYCLE t1 t2 $\cdots$ tn \/}: calculate rate constants
at the end of every cycle for temperatures {\it t1}, {\it t2}, etc.
Each temperature and forward and backward rate constants are dumped to 
file {\tt NGT.rates.new}.
Any number of temperatures can be specified, so long as continuation 
lines are used if the line length exceeds 80 characters. 
This keyword was introduced to make the LJ$_{38}$ demonstration cleaner.

\item {\it RBAA\/}: specifies the number of rigid bodies being considered in the angle-axis. NB: this is not part of the GENRIGID framework.

\item {\it RBSYM\/}: specifies that internal symmetry operations permuting equivalent sites for
rigid-body building blocks exist. The operations are read in from a file {\tt rbsymops}, which must
exist in the working directory. The first line of the file is an integer that specifies the number
of operations generated by proper axes of rotation including the identity operation; the operations
are then read in one at a time in a representation consisting of a unit vector, defining the
axis in the reference frame, and an angle in degrees, describing the magnitude of rotation about
that axis. The first operation has to correspond to the identity operation.

This keyword has to be combined with {\it PERMDIST\/} so that structures are aligned and
a distance metric considered based on permutations of identical rigid
bodies and any internal symmetry operation of each rigid body that is a symmetry
of the potential energy function. NB: this is not part of the GENRIGID framework.

\item {\it READMIN file\/}: reads in the data for one or more minima from {\it file}
in {\tt OPTIM} min.data.info format and then stops. 
Any number of min.data.info files can be concatenated into {\it file}.
New entries will be created in {\tt min.data} and {\tt points.min}.
If {\tt min.A} and {\tt min.B} do not exist they are not created.
{\it READMIN} therefore provides an alternative way to start an initial
path calculation by providing minima, so long as {\tt min.A} and {\tt min.B}
are created by hand.
It also provides a way to add additional minima to an existing database, since
new entries should be appended. There is a check to make sure that the minima
added are different from all those currently known.

\item {\it REGROUP x\/}: regroup the A and B sets using a disconnectivity graph 
analysis \cite{beckerk97,walesmw98,Wales03} at energy {\it x}. 
Any intervening minima that share a superbasin with an A or B minimum are reclassified
to belong to the A and B sets, respectively.\cite{TrygubenkoW06}
The number of minima and transition states {\it does not change}: only the
classification of minima as A or B is affected,
which will change any rate analysis that follows.
The corresponding
minima are printed in files {\tt min.A.regrouped} and {\tt min.B.regrouped}.

\item {\it REGROUPFREE x\/}: the database will be regrouped by combining free
energy minima where forward and backward free energy barriers are both
less than {\it x}. Regrouping is performed iteratively until no further free
energy minima merge. 
In this scheme, groups that contain product and reactant minima
(A and B sets) are not allowed to merge. 
The regrouping continues even if product and reactant groups
could merge according to the barrier threshold: such mergers are simply forbidden.
Don't forget to assign an appropriate value for the Planck constant using the
{\it PLANCK\/} keyword. 
If one of the {\it DIJKSTRA}, {\it SDGT}, {\it SGT}, or {\it DGT} keywords is
present the corresponding analysis will be performed using the new groups
and free energies.

\item {\it REGROUPFREEAB x\/}: the database will be regrouped as for
{\it REGROUPFREE\/} above, but only the A and B groups are changed.

\item {\it REGROUPPE x\/}: the database will be regrouped based upon 
a superbasin analysis at potential energy $x$.
Minima will be reassigned as A and B-type if they are in a superbasin
with an A or B minimum for this threshold.
New files {\tt min.data.regrouped}, {\tt ts.data.regrouped}, {\tt min.A.regrouped}
and {\tt min.B.regrouped} will be created.
Don't forget to assign an appropriate value for the Planck constant using the
{\it PLANCK\/} keyword. See also {\it REGROUPRATE\/}.
{\it REGROUPPE\/} and {\it REGROUPRATE\/} are different from {\it REGROUP\/}
in that they actually change the internal database structure into free energy
minima and groups of transition states linking them.
In this scheme, groups that contain product and reactant minima
(A and B sets) are not allowed to merge. 
The regrouping continues even if product and reactant groups
could merge according to the barrier threshold: such mergers are simply forbidden.
If one of the {\it DIJKSTRA}, {\it SDGT}, {\it SGT}, or {\it DGT} keywords is
present the corresponding analysis will be performed using the new groups
and free energies.

\item {\it REGROUPPERSIST thresh \/}: 
regrouping analogous to {\it REGROUPFREE} except that minima in groups defined
by the {\tt min.include} file (which contains some of the most persistent minima, see 
{\it PERSIST}) are also not allowed to merge, like the A and B
sets (unless {\it ALLOWAB} is set). The {\it PERSIST} keyword must also be present 
(though the code could easily be changed to use any pre-existing min.include file...).

\item {\it REGROUPRATE x\/}: the database will be regrouped based upon harmonic transition
state theory rate constants. Minima are in the same group if they can interconvert
via a path that involves only rate constants greater than $x$.
Minima will be reassigned as A and B-type if they are in a group
with an A or B minimum for this threshold.
New files {\tt min.data.regrouped}, {\tt ts.data.regrouped}, {\tt min.A.regrouped}
and {\tt min.B.regrouped} will be created.
Don't forget to assign an appropriate value for the Planck constant using the
{\it PLANCK\/} keyword. See also {\it REGROUPPE\/}.
{\it REGROUPPE\/} and {\it REGROUPRATE\/} are different from {\it REGROUP\/}
in that they actually change the internal database structure into free energy
minima and groups of transition states linking them.
In this scheme, groups that contain product and reactant minima
(A and B sets) are not allowed to merge. 
The regrouping continues even if product and reactant groups
could merge according to the barrier threshold: such mergers are simply forbidden.
If one of the {\it DIJKSTRA}, {\it SDGT}, {\it SGT}, or {\it DGT} keywords is
present the corresponding analysis will be performed using the new groups
and free energies.

\item {\it REMOVESP\/}: the minima specified in files {\tt min.remove} and
{\tt ts.remove} are removed and new files {\tt min.data.removed},
{\tt ts.data.removed}, {\tt min.A.removed}, {\tt min.B.removed},
{\tt points.min.removed} and {\tt points.ts.removed}
are created with a consistent numbering scheme for the remaining stationary
points. The first lines of {\tt min.remove} and
{\tt ts.remove} must contain a single integer, which is the number of 
stationary points listed for removal on the remaining lines.

\item {\it REMOVEUNCONNECTED set \/}: the database is rewritten to files
{\tt min.data.removed}, {\tt points.min.removed}, etc.
Minima disconnected from {\it set}, where {\it set\/} is A B or AB, 
are removed, along with all transition states that connect them.
Minima with {\it NCONNMIN} connections or fewer are also removed (this 
condition is applied recursively). The default for {\it set\/} is AB, which will remove
minima that have no connection to any member of the A or B sets.

\item {\it RETAINSP\/}: minima {\bf not} specified in file {\tt min.retain} 
are removed and new files {\tt min.data.retained},
{\tt ts.data.retained}, {\tt min.A.retained}, {\tt min.B.retained},
{\tt points.min.retained} and {\tt points.ts.retained}
are created with a consistent numbering scheme for the remaining stationary
points. The first line of {\tt min.retain} 
must contain a single integer, which is the number of 
minima listed on the remaining lines.
Transition states are only retained if they link two minima specified in the
{\tt min.retain} file. Note, however, that the conformations specified in
{\tt min.A} and {\tt min.B} have to be included in {\tt min.retained}. Otherwise, 
{\tt ts.data.retained} and {\tt points.ts.retained} are not created.

\item {\it REWEIGHT nrwbins nrwreactant energyfile\/}: 
conditional probabilities of reactant minima are obtained from the quench
probabilities calculated using the energies in file {\tt energyfile}.
These energies could come from systematic quenching from an MD trajectory at
the same temperature, for example.
{\it nrwbins\/} is the number of bins to use in representing the quench
probability distribution and {\it nrwreactant} is the number of bins
to use in representing the minima in the reactant set.
This is a somewhat experimental option. Consult DJW before using!

\item {\it RELATIVEE\/}: subtract the potential energy of the global minimum
from all the minima and transition states, as well as the treshold for
transition state neglect. This shift of the energy origin may
help to avoid some numerical underflow or overflow issues in rate
and therodynamics calculations, especially at
low temperature.
It can only be used in post-processing, since we shift only the potential energy
values that are read in initially.

\item {\it RFMULTI tau Tlow Thigh Tinc steps pfshift\/}: 
run the {\it REGROUPFREE\/} analysis as a function of temperature for a fixed
regrouping threshold. The threshold is determined from the observation time scale, {\it tau\/}
and the temperature range is {\it Tlow\/} to {\it Thigh\/} in {\it steps\/}
steps.
A fixed shift for the natural log of the partition functions can be specified
by the parameter {\it pfshift\/}, which may be needed to prevent underflow or overflow.

\item {\it RIGIDBODIES n\/}: specifies the number of rigid bodies; only one
of {\it NATOMS\/} and {\it RIGIDBODIES} should be present. NB: this is not part of the GENRIGID framework.

\item {\it RIGIDINIT n\/}: specifies the use of the generalised rigid body framework. You must also specify
the number of degrees of freedom in the rigidified system, {\it n}, so that {\tt PATHSAMPLE} knows how many 
eigenvalues to expect in {\tt OPTIM} output.

\item {\it SDGT DisconnectSources AltPbb Rescale Normalise\/}: 
graph transformation rate calculation, which switches from sparse optimised to
dense optimised algorithms when the average number of connections
exceeds a certain threshold \cite{TrygubenkoW06}.
The four arguments are all logicals, so an example input line might look
\vbox{SDGT T T F F}. If true (the default) {\it DisconnectSources} specifies that
a full transformation should be performed for each source, disconnecting the 
other sources. The resulting rate constants correspond to the KMC result and
$k^{\rm KMC}$ \cite{Wales06}.
If {\it AltPbb\/} is true (default is false) then additional work is done to
maintain precision, which roughly doubles the execution time, but may be needed at low
temperature.
If {\it Rescale} is true (default false) an alternative strategy is used 
to try and prevent error propagation.
Setting {\it Normalise} true (default false) instructs {\tt GT2input.f90} to check the normalisation
of branch probabilities. This should not be necessary.

\item {\it SEED n\/}: random number seed.

\item {\it SGT DisconnectSources AltPbb Rescale Normalise\/}: 
sparse optimised graph transformation rate calculation \cite{TrygubenkoW06}.
The four arguments are all logicals, so an example input line might look
\vbox{SGT T T F F}. If true (the default) {\it DisconnectSources} specifies that
a full transformation should be performed for each source, disconnecting the 
other sources. The resulting rate constants correspond to the KMC result and
$k^{\rm KMC}$ \cite{Wales06}.
If {\it AltPbb\/} is true (default is false) then additional work is done to
maintain precision, which roughly doubles the execution time, but may be needed at low
temperature.
If {\it Rescale} is true (default false) an alternative strategy is used 
to try and prevent error propagation.
Setting {\it Normalise} true (default false) instructs {\tt GT2input.f90} to check the normalisation
of branch probabilities. This should not be necessary.

\item {\it SHANNON tmin tmax tinc einc npeq\/}: 
calculate frustration measures for the landscape as a function of temperature,
starting from {\it tmin} (default 1), ending at {\it tmax} (default 2)
at intervals {\it tinc} (default 0.1).
{\it einc} is the energy interval for superbasin construction, used to estimate the
barriers.
{\it npeq} (default 100) is the number of minima to include in maintaining an ordered list of the
highest occupation probabilities. 
These probabilities are printed, and they are used in the more expensive rate-based measures
that are computed for {\it SHANNONR}.

\item {\it SHANNONR tmin tmax tinc einc npeq\/}:
calculate frustration measures for the landscape as a function of temperature,
starting from {\it tmin} (default 1), ending at {\it tmax} (default 2)
at intervals {\it tinc} (default 0.1).
As for {\it SHANNON}, but the more expensive rate-based metrics are calculated.
{\it einc} is the energy interval for superbasin construction, used to estimate the
barriers.
{\it npeq} (default 100) is the number of minima to include in maintaining an ordered list of the
highest occupation probabilities.

\item {\it SHORTCUT minsep string\/}: try connecting minima that are further apart than {\it minsep\/}
steps on the best path, as calculated using Dijkstra's algorithm.
In the Dijkstra analysis minima with zero connections are removed. 
This value can be changed using a {\it DIJKSTRA n} line in {\tt pathdata}.
If the option argument {\it string\/} is set to {\it BARRIER\/} or {\it RATE\/} then
the strategy is different. We now look for pairs of minima on either side of
the highest barriers or minima linked by the smallest
rate constant on the best path, sorted according to the barrier height or the rate.
{\it minsep\/} is then used to define the largest number of steps away from 
the transition states for connection attempts.

\item {\it SKIPPAIRS \/}: do not attempt to connect a pair of minima if they are already connected. This is used only with USEPAIRS. Pairs which are rejected on these grounds DO count towards the total number of connections provided by the CYCLES keyword, however the debug printing doesn't recognise that at the present time.

\item {\it SLEEPTIME x \/}: set the time used in the system sleep calls
between submission of {\tt OPTIM} jobs. The default value is 1\,s. A nonzero
value is needed for small systems on distributed memory machines to prevent
us from running out of ports. A value of zero on a shared memory system can
speed up execution significantly for small systems.

\item {\it SLURM \/}: OPTIM jobs are submitted to nodes using srun when the queueing system is SLURM. This is intended to replace the use of keywords SSH and PBS on clusters using SLURM. Job submission using ssh causes problems with CUDAOPTIM jobs on pat, so keyword SLURM must be used alongside keyword CUDA. 

\item {\it SSH \/}: OPTIM jobs are submitted to nodes using ssh rather than rsh (default)

\item {\it ST \/}: calls a finite system of Stockmayer particles.

\item {\it STARTFROMPATH afile n1 n2 \/}: reads an initial path from file {\tt afile}. 
% If this 
% file is in {\it DUMPALLPATHS} format then the keyword {\it STARTTRIPLES} is also needed.
The files {\tt min.A} and {\tt min.B} are created: {\tt min.A} contains the entries
1 and {\it n1} and {\tt min.B} contains the entries 1 and {\it n2}.
If {\tt min.A} already exists then the run will terminate with a warning message
without overwriting it.

% \item {\it STARTTRIPLES\/}: reads the initial path specified by
% {\it STARTFROMPATH a\/} from  file {\tt path.info.a} in the new {\it DUMPALLPATHS} format.

\item {\it SYSTEM a\/}: the atom type label to be written to {\tt odata} files for {\tt OPTIM},
thus specifying the potential that {\tt OPTIM} will use.

\item {\it TAG n x\/}: atom number {\it n\/} in the system is `tagged' by giving it 
an artificial mass {\it x\/}.

\item {\it TEMPERATURE x\/}: specifies that the canonical ensemble at reduced temperature {\it x\/}
is to be used to calculate rate constants. Mutually exclusive with {\it ENERGY\/}.

\item {\it TRAP\/}: specifies a trapped ion potential. This keyword is needed to set the
number of zero eigenvalues. See the coresponding keyword in {\tt OPTIM} for more information.

% \item {\it TRIPLES\/}: specifies that {\tt path.info} files read after startup 
% have the new {\it DUMPALLPATHS} format. Use {\it STARTTRIPLES} and {\it ADDTRIPLES} to
% read or add a single {\tt path.info} file in this format at the beginning of a run.

\item {\it TSTHRESH x\/}: specifies that transition states above energy $x$ should
not be included in the database. Probably most useful with CHARMM, where genuine 
transition states with silly energies can certainly occur and give rise to underflow.

\item {\it TWOD\/}: the system is two-dimensional.

\item {\it UNRES\/}: specifies the UNRES potential.\cite{liwoopwrs97} % ,liwopwros97,liwokcgowrps98}

\item {\it UNTRAP einc thresh {\it edeltamin elowbar ehighbar}\/}: try connecting minima to eliminate traps.
Connections are attempted between all minima and any of the minima in the
product set based on the largest barriers in the product direction, as estimated
from disconnectivity analysis at energy intervals of $einc$, starting from the
global minimum.
The product basin is defined as the set at the highest energy for which the 
minimum in question is not a member.
Candidate pairs of minima are sorted based upon the ratio of the
potential energy barrier to the potential energy difference between the minimum
in question and the lowest product minimum.
Hence this scheme is analogous to the {\it FREEPAIRS\/} procedure, but
uses individual minima and potential energy, instead of free energy.
The original product minimum may be replaced by a minimum from
the same superbasin that is closer to the target minimum, so long as it
lies within an energy $thresh$ above the minimum to be untrapped. 
Minima with zero connections are not considered; 
this value can be changed using a {\it DIJKSTRA n} line in {\tt pathdata}, even
though a Dijkstra analysis is not used.
See also the {\it PAIRLIST\/} keyword.
The {\it UNTRAP \/} keyword may provide the best way to remove artificial 
frustration from potential energy disconnectivity graphs.
It may be helpful to choose a larger value of {\it einc\/} than would be
used for the superbasin analysis in visualising the disconnectivity graph.
This will encourage connection attempts with minima of lower energy in the
expanded product superbasin. 
The optional arguments {\it edeltamin\/} and {\it elowbar\/} are useful for databases 
without a well-defined global minimum. If the potential energy difference between the minimum
in question and the lowest product minimum is less than {\it edeltamin\/}, the value of 
{\it edeltamin\/} is substituted for this difference. This substitution prevents 
connection attempts to minima connected by low barriers but with a very small 
energy difference to the lowest product minimum.  If the barrier from the lowest product minimum to the minimum in question is less than {\it elowbar\/}, a value of TINY(1.0D0) is given to the barrier instead. This substitution prevents connection attempts to minima connected
by low barriers.
The fifth optional argument {\it ehighbar} aids with the selection of minima for
untrapping if you wish to target particular regions. Minima with a barrier height (in the direction
of the lowest-energy product minimum) larger than EHIGHBAR will not be selected.

Sometimes there are large groups of minima separated by small barriers that form a trap. We only need to find a lower-energy path for one of these minima and untrapping all of them may be a wasted effort. Running disconnectionDPS with the keyword BASINT followed by a particular energy gives the results of a basin analysis at this energy in a file `basins'. If this file is renamed as `noduplicatebasins' and placed in the directory where the PATHSAMPLE job is running, untrap will only pick one minimum from this group for untrapping.

\item {\it UNTRAPMETRIC nitems nmatrix {\it baildist}\/}: to be used with {\it UNTRAP}. {\it nitems} is the number of metrics to use (1,2 or 3), {\it nmatrix} is the number of closest minima for which distances are calculated (default 2000) and {\it baildist} is a distance limit, if any distance is found to be below this limit, no further pairs are tried (default TINY(1.0D0)).

To use this keyword a `metric' file is required. The `metric' file takes the following format, with one line entry for each minimum in the database:
metric1 nmin [metric2] [metric3], metric1 takes priority over metric 2 etc...
You have to construct this file manually with your own choice of metric(s).

You also need a `metric.ordered' file - this speeds up the finding of pairs.
In /SCRIPTS/PATHSAMPLE/ there is a program to convert the metric file and produce a metric.ordered file, `getmetricordered.f90'.
However, you won't normally want all minima in the `metric.ordered' file. Ideally, this is a list of minima in the main basin to which connection attempts should be made, usually the main basin can be defined by an high energy cutoff.
Running disconnectionDPS with the keyword BASINT followed by a particular energy gives the results of a basin analysis at this energy in a file `basins'.
`getmetricordered.f90' will produce a `metric.ordered' file from `metric' and `basins', if you set the required input arguments.
The metric and metric.ordered files must be constructed manually and are currently not updated during a run when minima are added to the database.
Different metrics are required for different systems.

\item {\it USEPAIRS Epathfile\/}: pairs of minima are chosen for connection attempts based
on the order of local minima specified in file {\tt Epathfile}, which must have the format
of a {\tt PATHSAMPLE} {\tt Epath} output file 9as generated by {\it DIJKSTRA\/}, etc.
This keyword is intended to follow a {\it DUMMYTS\/} run, where the stationary point
database has been refined using {\it BHINTERP\/} or {\it BISECT\/} runs in {\tt OPTIM}.
The dummy {\tt ts.data} and {\tt pairs.data} files must be renamed or removed
before the {\it USEPAIRS\/} run.
The pairs of minima are first chosen to be the adjacent structures from the list, then
second-neighbours, until all possible pairs have been tried.
This keyword can also be used to specify a list of pairs to attempt to connect. See the MAKEPAIRS keyword to help assemble {\tt Epathfile} in this case.

\end{itemize}
% </kwd>
\section{{\tt odata} files}
\label{sec:odatafiles}

The following {\tt odata} template
files may be necessary, one for each type of {\tt OPTIM} job which can be launched by {\tt PATHSAMPLE}.
If {\it CONNECTIONS} is set to one or fewer then only an {\tt odata.connect} template is
needed.
\smallskip
\begin{itemize}
\item {\tt odata.connect}: the template file for double-ended pathway searches.

\item {\tt odata.path}: template for pathway calculations to find the two minima connected by
steepest-descent paths to a single transition state. Reads in the eigenvector corresponding to
the negative eigenvalue (transition mode) from file {\tt vector.dump} produced by {\tt odata.tssearch}.

\item {\tt odata.tssearch}: performs a single-ended transition state search.

\end{itemize}

Please refer to the {\tt OPTIM} manual\cite{optim} for details of {\tt odata} files.
In the templates the {\tt odata} file should not contain any coordinates, and should terminate
with the {\it POINTS} or {\it CHARMM} keyword, as appropriate.
\pagebreak

\section{Output files}
\label{sec:output}

{\tt PATHSAMPLE} produces information about its progress on standard output;
more details can be obtained with the {\it DEBUG} keyword. 
The databases of minima and
transition states ({\tt min.data}, {\tt ts.data}, {\tt points.min} and {\tt points.ts}) described in
\S\ref{sec:input} are updated as necessary. 

\section{ A Note on Units and Planck's Constant}
\label{sec:units}

Aside from {\it CHARMM} and {\it AMBER} {\tt OPTIM} does no
unit conversions. These systems are treated differently, as explained below.
For all other cases {\tt PATHSAMPLE} is
expecting to receive $\ln\Pi_i \omega^2_i$ in the {\tt min.data}
and {\tt ts.data} files. {\tt PATHSAMPLE} converts $\omega$ to
$\nu$ using $\nu=\omega/2\pi$, but also does no unit conversions.
The rate constants are therefore in natural frequency units of
$\sqrt{\epsilon/m\sigma^2}$, where $\epsilon$ is the unit of energy,
$m$ is the unit of mass, and $\sigma$ is the unit of length.

For a system where all particles have equal masses, $m$, the rate constants
calculated by {\tt PATHSAMPLE} can therefore be converted to SI units
by multiplying by $\sqrt{(\epsilon/{\rm J})/(m/{\rm kg})(\sigma/{\rm m})^2}$.

For calculations involving free energy regrouping schemes we need to supply
a value for the Planck constant in reduced units via the {\it PLANCK} keyword.
Since the temperature is read in energy units, i.e.~$\epsilon$, so that $k_BT$
is in $\epsilon$, we need to define $h$ in reduced units so that terms like
$k_BT/h\nu$ are dimensionless. If $\nu$ is in reduced time units then we
need $(h/{\rm Js})$ divided by the unit of energy and the unit of time. 
The reduced value of $h$ is therefore
\begin{equation}
\frac{(h/{\rm Js})}{(\epsilon/{\rm J})
\sqrt{\displaystyle\frac{(m/{\rm kg})(\sigma/{\rm m})^2}{(\epsilon/{\rm J})}}} 
= \frac{(h/{\rm Js})}{\sqrt{(m/{\rm kg})(\sigma/{\rm m})^2(\epsilon/{\rm J})}}.
\end{equation}

For {\it CHARMM} and {\it AMBER} we need to diagonalise the reciprocal
mass-weighted Hessian in {\tt OPTIM}, where the various masses are known.
For convenience the frequency unit conversion is done in {\tt OPTIM} as
well, so that the rate constants calculated in {\tt PATHSAMPLE} are
in s$^{-1}$ and do not need to be converted.
The value required for the Planck constant is therefore different because
$\nu$ is not in reduced units. Instead, we need to convert $(h/{\rm Js})(\nu/{\rm s}^{-1})$
to kcal/mol, since these are the units of $k_BT$. Hence we need $(h/{\rm Js})/(\epsilon/{\rm J})$,
where $\epsilon$ is one kcal/mol. Since 1\,kcal/mol is $6.948\times10^{-21}\,$J
the required value for the {\it PLANCK\/} keyword in regrouping calculations
is $6.626\times10^{-34}/6.948\times10^{-21}=9.536\times10^{-14}$.


\section{Known Problems}
\label{sec:problems}

If all {\tt OPTIM} jobs are failing for some reason then it is likely
that the rsh command that starts the jobs on remote nodes will run out of
sockets. Using a single rsh command together with cp via nfs to copy results
back seems to have eliminated the previous problems that we sometimes saw
with socket errors.

Rate constant calculations with any graph transformation variant can be very
memory hungry. They will die with a segmentation fault if they run out
of memory.

%<examples>
\section{Example {\tt pathdata} files}
\label{sec:example}
\subsection{Starting from an {\tt OPTIM} {\tt path.info} file}

The following {\tt pathdata} file was used on a distributed memory machine.
It loads an initial path from {\tt path.info.startup} and creates {\tt min.A}
and {\tt min.B} files containing the entries 1 and 9 and 1 and 16, respectively.
1000 iterations of the committor probabilities are performed every cycle,
removing minima with one connection or fewer, and using a successive
overrelaxation parameter of 1.99.
Rate constants are calculated using graph transformation every 10 cycles,
again removing minima with one connection or fewer.
\medskip

\begin{table}[H]
\begin{center}
\begin{tabular}{ll}
%JOBSPERNODE & 2 \\
NATOMS       &  56 \\
SYSTEM        & BL \\
STARTFROMPATH & startup 9 16 \\
COMMENT & ADDPATH add \\
GT & 1 10 \\
TEMPERATURE&    0.42 \\
DSCALE      &    3.0 \\
PSCALE       &   1.0 \\
PFOLD         &  1000 1 1.99 \\
CYCLES      &    500 \\
CONNECTIONS  &  1 \\
SEED      &     1 \\
PERTURB    &    0.3D0 \\
ETOL        &   0.0000005D0 \\
ITOL        &   0.1 \\
DIRECTION    &  AB \\
EXEC        &   /home/wales/bin/OPTIM.3.2 
\end{tabular}
\end{center}
\end{table}

\subsection{Starting from {\tt OPTIM} {\tt min.data.info} files}

It is also possible to start {\tt PATHSAMPLE} runs without an existing 
connection between the end points of interest. See keywords {\it DIJINITSTART\/}
and {\it DIJINITCONT\/}.
In this example we set up {\tt PATHSAMPLE} from {\tt min.data.info} files for the 
two minima and use {\it DIJINITCONT\/} to continue the run and seek an initial 
connection using {\tt PATHSAMPLE}.

First, a minimisation was run for each minimum using {\tt OPTIM} with the
{\it DUMPDATA} keyword set. The {\it ENDHESS} keyword was used to produce frequencies after a
{\it BFGSMIN\/} optimisation.
In a clean directory, with no preexisting {\tt PATHSAMPLE} files, two entries were created
in {\tt min.data} and {\tt points.min} using the {\tt PATHSAMPLE} {\it READMIN\/} keyword
to read each of the {\tt min.data.info} files in turn. {\tt min.A} and {\tt min.B} files were
then created using vi with one entry in each, pointing to minima 1 and 2, respectively. 
After creating a suitable {\tt odata.connect} file a single cycle of {\tt PATHSAMPLE}
was then run on one core to populate the database with enough minima to run on
multiple cores in subsequent connection attempts. Since there is only one possible connection
to try in the first cycle, it is necessary to use a single processor in this case
along with the {\it DIJINITCONT\/} keyword in {\tt pathdata}. A couple of cycles on
eight cores then produced a connection for this bulk BLJ$_{60}$ example.
\medskip

\begin{table}[H]
\begin{center}
\begin{tabular}{ll}
NATOMS   &      60 \\
COPYFILES & perm.allow \\
BULK  & 3.587037905 3.587037905 3.587037905 \\
PERMDIST \\
SYSTEM  &       LS \\
TEMPERATURE &   0.71 \\
CONNECTIONS &   1 \\
SEED        &   1 \\
PERTURB     &   0.40 \\
ETOL        &   1.0D-7  \\
ITOL        &   1.1D0 \\
GEOMDIFFTOL        &   0.1D0  \\
DIRECTION   &   AB \\
EXEC        &  /home/wales/bin/OPTIM \\
 & \\
comment READMIN min.data.info.start \\
comment READMIN min.data.info.finish \\
comment CPUS 1 \\
 & \\
DIJINITCONT EXP \\
CYCLES        100 \\
%JOBSPERNODE 1 \\
PAIRLIST 1
\end{tabular}
\end{center}
\end{table}
\medskip

The commented lines were used to read in the initial {\tt min.data.info} files.
A similar procedure can be used if an initial {\tt path.info} file is available
without a complete connection between the desired end points.

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}

\input{jnames}
\bibliographystyle{thesis}
\bibliography{PATHSAMPLEdoc}
% </examples>
\end{document}
% </end>
% </document>


